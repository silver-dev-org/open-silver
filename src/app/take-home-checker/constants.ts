import { Score, TakeHome, TakeHomeAnalysis } from "./types";
import { takeHomeToXML } from "./utils";

const examples: {
  takeHome: TakeHome;
  analysis: TakeHomeAnalysis;
}[] = [
  {
    takeHome: {
      code: [
        {
          path: "homevision-checkbox-detector-main/solution/api/server.py",
          content:
            '#!/usr/bin/env python3\n\nimport os\nimport sys\nimport uuid\nimport base64\nfrom pathlib import Path\nfrom datetime import datetime\nfrom flask import Flask, request, jsonify\nfrom flask_cors import CORS\nimport cv2\nimport numpy as np\nimport sqlite3\nimport json\nfrom dataclasses import dataclass\nfrom typing import Dict, Tuple, List, Optional\nimport tempfile\n\n# Add parent directory to path\nsys.path.append(str(Path(__file__).resolve().parent.parent / "common"))\n\n# Import the CheckboxChecker\nfrom form_cv.form_cv import CheckboxChecker\n\napp = Flask(__name__)\nCORS(app)  # Enable CORS for all routes\n\n# Create uploads directory if it doesn\'t exist\nUPLOAD_DIR = Path(__file__).parent / "uploads"\nUPLOAD_DIR.mkdir(exist_ok=True)\n\n# Database setup\nDB_PATH = Path(__file__).parent / "form_computer_vision.db"\n\ndef init_db():\n    """Initialize the database with the required tables."""\n    conn = sqlite3.connect(str(DB_PATH))\n    c = conn.cursor()\n    \n    # Create table for storing detection results\n    c.execute(\'\'\'\n    CREATE TABLE IF NOT EXISTS detection_results (\n        id TEXT PRIMARY KEY,\n        filename TEXT NOT NULL,\n        timestamp TEXT NOT NULL,\n        min_size INTEGER NOT NULL,\n        max_size INTEGER NOT NULL,\n        threshold REAL NOT NULL,\n        padding INTEGER NOT NULL,\n        image_path TEXT NOT NULL,\n        result_json TEXT NOT NULL\n    )\n    \'\'\')\n    \n    conn.commit()\n    conn.close()\n\n# Initialize the database\ninit_db()\n\n@dataclass\nclass DetectionResult:\n    """Class for storing detection results."""\n    id: str\n    filename: str\n    timestamp: str\n    min_size: int\n    max_size: int\n    threshold: float\n    padding: int\n    image_path: str\n    result_json: str\n    \n    @property\n    def result(self) -> Dict:\n        """Parse and return the JSON result."""\n        return json.loads(self.result_json)\n    \n    def to_dict(self) -> Dict:\n        """Convert the detection result to a dictionary."""\n        return {\n            "id": self.id,\n            "filename": self.filename,\n            "timestamp": self.timestamp,\n            "min_size": self.min_size,\n            "max_size": self.max_size,\n            "threshold": self.threshold,\n            "padding": self.padding,\n            "image_path": self.image_path,\n            "result": self.result\n        }\n\ndef save_detection_result(\n    filename: str,\n    min_size: int,\n    max_size: int,\n    threshold: float,\n    padding: int,\n    image_path: str,\n    result: Dict\n) -> str:\n    """Save detection result to the database."""\n    detection_id = str(uuid.uuid4())\n    timestamp = datetime.now().isoformat()\n    \n    conn = sqlite3.connect(str(DB_PATH))\n    c = conn.cursor()\n    \n    c.execute(\'\'\'\n    INSERT INTO detection_results\n    (id, filename, timestamp, min_size, max_size, threshold, padding, image_path, result_json)\n    VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)\n    \'\'\', (\n        detection_id,\n        filename,\n        timestamp,\n        min_size,\n        max_size,\n        threshold,\n        padding,\n        image_path,\n        json.dumps(result)\n    ))\n    \n    conn.commit()\n    conn.close()\n    \n    return detection_id\n\ndef get_detection_results() -> List[DetectionResult]:\n    """Get all detection results from the database."""\n    conn = sqlite3.connect(str(DB_PATH))\n    conn.row_factory = sqlite3.Row\n    c = conn.cursor()\n    \n    c.execute(\'SELECT * FROM detection_results ORDER BY timestamp DESC\')\n    rows = c.fetchall()\n    \n    results = []\n    for row in rows:\n        results.append(DetectionResult(\n            id=row[\'id\'],\n            filename=row[\'filename\'],\n            timestamp=row[\'timestamp\'],\n            min_size=row[\'min_size\'],\n            max_size=row[\'max_size\'],\n            threshold=row[\'threshold\'],\n            padding=row[\'padding\'],\n            image_path=row[\'image_path\'],\n            result_json=row[\'result_json\']\n        ))\n    \n    conn.close()\n    \n    return results\n\ndef get_detection_result(detection_id: str) -> Optional[DetectionResult]:\n    """Get a detection result by ID."""\n    conn = sqlite3.connect(str(DB_PATH))\n    conn.row_factory = sqlite3.Row\n    c = conn.cursor()\n    \n    c.execute(\'SELECT * FROM detection_results WHERE id = ?\', (detection_id,))\n    row = c.fetchone()\n    \n    if row is None:\n        return None\n    \n    result = DetectionResult(\n        id=row[\'id\'],\n        filename=row[\'filename\'],\n        timestamp=row[\'timestamp\'],\n        min_size=row[\'min_size\'],\n        max_size=row[\'max_size\'],\n        threshold=row[\'threshold\'],\n        padding=row[\'padding\'],\n        image_path=row[\'image_path\'],\n        result_json=row[\'result_json\']\n    )\n    \n    conn.close()\n    \n    return result\n\n@app.route(\'/api/detect\', methods=[\'POST\'])\ndef detect_checkboxes():\n    """Detect checkboxes in an uploaded image."""\n    # Check if image file is included in the request\n    if \'image\' not in request.files:\n        return jsonify({"error": "No image file provided"}), 400\n    \n    image_file = request.files[\'image\']\n    if image_file.filename == \'\':\n        return jsonify({"error": "No selected file"}), 400\n    \n    # Get parameters from the request\n    min_size = int(request.form.get(\'min_size\', 20))\n    max_size = int(request.form.get(\'max_size\', 50))\n    threshold = float(request.form.get(\'threshold\', 0.3))\n    padding = int(request.form.get(\'padding\', 10))\n\n    \n    # Generate a unique filename and save the uploaded image\n    filename = f"{uuid.uuid4()}_{image_file.filename}"\n    image_path = str(UPLOAD_DIR / filename)\n    image_file.save(image_path)\n    \n    try:\n        # Read the image and convert to grayscale\n        img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n        if img is None:\n            return jsonify({"error": "Failed to process image"}), 400\n        \n        # Create a CheckboxChecker instance\n        checker = CheckboxChecker(img)\n        \n        # Detect checkboxes\n        checker.detect_checkboxes(min_size=min_size, max_size=max_size)\n        \n        # Get checkbox states\n        checkbox_states = checker.get_checkbox_states(threshold=threshold, padding_percent=padding)\n        \n        # Prepare result\n        result = {}\n        for cb_id, (x, y, w, h, is_checked) in checkbox_states.items():\n            result[str(cb_id)] = {\n                "position": {"x": x, "y": y},\n                "size": {"width": w, "height": h},\n                "checked": True if is_checked else False\n            }\n        \n        # Generate visualization\n        vis_image = cv2.cvtColor(img.copy(), cv2.COLOR_GRAY2BGR)\n        for cb_id, (x, y, w, h, is_checked) in checkbox_states.items():\n            color = (0, 255, 0) if is_checked else (0, 0, 255)  # Green for checked, Red for unchecked\n            cv2.rectangle(vis_image, (x, y), (x+w, y+h), color, 2)\n            text = f"{cb_id}: {\'Checked\' if is_checked else \'Unchecked\'}"\n            cv2.putText(vis_image, text, (x, y-5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 1)\n        \n        # Save visualization image\n        vis_filename = f"vis_{filename}"\n        vis_path = str(UPLOAD_DIR / vis_filename)\n        cv2.imwrite(vis_path, vis_image)\n        \n        # Save result to database\n        detection_id = save_detection_result(\n            filename=image_file.filename,\n            min_size=min_size,\n            max_size=max_size,\n            threshold=threshold,\n            padding=padding,\n            image_path=image_path,\n            result=result\n        )\n        \n        # Create base64 image for visualization\n        _, buffer = cv2.imencode(\'.png\', vis_image)\n        vis_base64 = base64.b64encode(buffer).decode(\'utf-8\')\n        \n        return jsonify({\n            "id": detection_id,\n            "filename": image_file.filename,\n            "timestamp": datetime.now().isoformat(),\n            "min_size": min_size,\n            "max_size": max_size,\n            "threshold": threshold,\n            "padding": padding,\n            "result": result,\n            "visualization": vis_base64,\n            "checkbox_count": len(checkbox_states)\n        })\n    \n    except Exception as e:\n        print(f"Error: {e}")\n        return jsonify({"error": str(e)}), 500\n\n@app.route(\'/api/results\', methods=[\'GET\'])\ndef get_results():\n    """Get all detection results."""\n    results = get_detection_results()\n    return jsonify([result.to_dict() for result in results])\n\n@app.route(\'/api/results/<detection_id>\', methods=[\'GET\'])\ndef get_result(detection_id):\n    """Get a detection result by ID."""\n    result = get_detection_result(detection_id)\n    \n    if result is None:\n        return jsonify({"error": "Result not found"}), 404\n    \n    # Check if the image file exists\n    image_path = Path(result.image_path)\n    if image_path.exists():\n        # Load the image for visualization\n        img = cv2.imread(str(image_path), cv2.IMREAD_GRAYSCALE)\n        \n        # Create visualization\n        vis_image = cv2.cvtColor(img.copy(), cv2.COLOR_GRAY2BGR)\n        for cb_id, data in result.result.items():\n            x = data["position"]["x"]\n            y = data["position"]["y"]\n            w = data["size"]["width"]\n            h = data["size"]["height"]\n            is_checked = data["checked"]\n            \n            color = (0, 255, 0) if is_checked else (0, 0, 255)\n            cv2.rectangle(vis_image, (x, y), (x+w, y+h), color, 2)\n            text = f"{cb_id}: {\'Checked\' if is_checked else \'Unchecked\'}"\n            cv2.putText(vis_image, text, (x, y-5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 1)\n        \n        # Create base64 image for visualization\n        _, buffer = cv2.imencode(\'.png\', vis_image)\n        vis_base64 = base64.b64encode(buffer).decode(\'utf-8\')\n        \n        # Add visualization to result\n        result_dict = result.to_dict()\n        result_dict["visualization"] = vis_base64\n        \n        return jsonify(result_dict)\n    \n    return jsonify(result.to_dict())\n\n@app.route(\'/api/health\', methods=[\'GET\'])\ndef health_check():\n    """Health check endpoint."""\n    return jsonify({"status": "ok"})\n\nif __name__ == \'__main__\':\n    app.run(debug=True, host=\'0.0.0.0\', port=5000)\n',
        },
        {
          path: "homevision-checkbox-detector-main/solution/cli/form_cv_cli.py",
          content:
            '#!/usr/bin/env python3\n\nimport os\nimport sys\nimport typer\nfrom pathlib import Path\nfrom typing import Optional, List\nimport cv2\nfrom rich.console import Console\nfrom rich.table import Table\nfrom rich.panel import Panel\nfrom rich.progress import Progress\nimport numpy as np\nfrom enum import Enum\n\nsys.path.append(str(Path(__file__).resolve().parent.parent / "common"))\n\n# Import the CheckboxChecker directly using the package structure\nfrom form_cv.form_cv import CheckboxChecker\n\n# Initialize Typer app with rich completion\napp = typer.Typer(\n    help="Form CV CLI",\n    add_completion=True,\n    rich_markup_mode="rich",\n)\nconsole = Console()\n\nclass OutputFormat(str, Enum):\n    """Output format options"""\n    TEXT = "text"\n    JSON = "json"\n    CSV = "csv"\n\ndef validate_file(file_path: Path):\n    """Validate that the file exists and is an image"""\n    # Try both as absolute path and relative to current directory\n    absolute_path = Path(file_path).resolve()\n    relative_path = Path(os.getcwd()) / file_path\n    \n    if absolute_path.exists():\n        return absolute_path\n    elif relative_path.exists():\n        return relative_path\n    else:\n        console.print(f"[bold red]Error:[/bold red] File {file_path} does not exist (tried both absolute and relative paths).")\n        raise typer.Exit(1)\n\n@app.command()\ndef check(\n    image_path: Path = typer.Argument(\n        ..., \n        help="Path to the form image to check", \n        exists=True,\n        dir_okay=False,\n        file_okay=True,\n        readable=True,\n        resolve_path=True,\n    ),\n    min_size: int = typer.Option(\n        20, \n        "--min-size", \n        "-m", \n        help="Minimum size of checkbox to detect"\n    ),\n    max_size: int = typer.Option(\n        50, \n        "--max-size", \n        "-M", \n        help="Maximum size of checkbox to detect"\n    ),\n    threshold: float = typer.Option(\n        0.3, \n        "--threshold", \n        "-t", \n        help="Threshold for determining if a checkbox is checked",\n        min=0.0,\n        max=1.0,\n    ),\n    padding: int = typer.Option(\n        10, \n        "--padding", \n        "-p", \n        help="Padding percentage for the checkbox ROI",\n        min=0,\n        max=100,\n    ),\n    output: OutputFormat = typer.Option(\n        OutputFormat.TEXT, \n        "--output", \n        "-o", \n        help="Output format",\n        case_sensitive=False,\n    ),\n    visualize: bool = typer.Option(\n        False, \n        "--visualize", \n        "-v", \n        help="Visualize the checkboxes on the image"\n    ),\n    save_path: Optional[Path] = typer.Option(\n        None, \n        "--save", \n        "-s", \n        help="Save the visualized image to this path"\n    ),\n):\n    """\n    Check form checkboxes in an image and determine if they are checked or not.\n    """\n    # Validate the image file\n    validate_file(image_path)\n    \n    with Progress() as progress:\n        task1 = progress.add_task("[green]Loading image...", total=1)\n        \n        # Read the image as grayscale\n        try:\n            image = cv2.imread(str(image_path), cv2.IMREAD_GRAYSCALE)\n            if image is None:\n                console.print(f"[bold red]Error:[/bold red] Failed to read image {image_path}")\n                raise typer.Exit(1)\n            checker = CheckboxChecker(image)\n            progress.update(task1, advance=1)\n        except Exception as e:\n            console.print(f"[bold red]Error:[/bold red] {str(e)}")\n            raise typer.Exit(1)\n        \n        task2 = progress.add_task("[green]Detecting checkboxes...", total=1)\n        try:\n            checker.detect_checkboxes(min_size=min_size, max_size=max_size)\n            progress.update(task2, advance=1)\n        except Exception as e:\n            console.print(f"[bold red]Error:[/bold red] {str(e)}")\n            raise typer.Exit(1)\n        \n        task3 = progress.add_task("[green]Analyzing checkbox states...", total=1)\n        # Get checkbox states\n        try:\n            checkbox_states = checker.get_checkbox_states(threshold=threshold, padding_percent=padding)\n            progress.update(task3, advance=1)\n        except Exception as e:\n            print(e)\n            console.print(f"[bold red]Error:[/bold red] {str(e)}")\n            raise typer.Exit(1)\n    \n    # Display the results\n    if output == OutputFormat.TEXT:\n        if not checkbox_states:\n            console.print(Panel("[yellow]No checkboxes found in the image.[/yellow]", title="Results"))\n        else:\n            table = Table(title=f"Checkbox Results - {image_path.name}")\n            table.add_column("ID", style="cyan", no_wrap=True)\n            table.add_column("Position (x, y)", style="magenta")\n            table.add_column("Size (w, h)", style="blue")\n            table.add_column("Status", style="green")\n            \n            for cb_id, (x, y, w, h, is_checked) in checkbox_states.items():\n                status = "[green]✓ Checked[/green]" if is_checked else "[red]✗ Unchecked[/red]"\n                table.add_row(\n                    str(cb_id),\n                    f"({x}, {y})",\n                    f"({w}, {h})",\n                    status\n                )\n            \n            console.print(table)\n            console.print(f"Total checkboxes found: [bold]{len(checkbox_states)}[/bold]")\n            \n    elif output == OutputFormat.JSON:\n        import json\n        result = {}\n        for cb_id, (x, y, w, h, is_checked) in checkbox_states.items():\n            result[cb_id] = {\n                "position": {"x": x, "y": y},\n                "size": {"width": w, "height": h},\n                "checked": is_checked\n            }\n        console.print(json.dumps(result, indent=2))\n        \n    elif output == OutputFormat.CSV:\n        console.print("id,x,y,width,height,checked")\n        for cb_id, (x, y, w, h, is_checked) in checkbox_states.items():\n            console.print(f"{cb_id},{x},{y},{w},{h},{is_checked}")\n    \n    if visualize or save_path:\n        vis_image = cv2.cvtColor(image.copy(), cv2.COLOR_GRAY2BGR)\n        \n        # Draw checkboxes on the image\n        for cb_id, (x, y, w, h, is_checked) in checkbox_states.items():\n            color = (0, 255, 0) if is_checked else (0, 0, 255)  # Green for checked, Red for unchecked\n            cv2.rectangle(vis_image, (x, y), (x+w, y+h), color, 2)\n            \n            # Add text label\n            text = f"{cb_id}: {\'Checked\' if is_checked else \'Unchecked\'}"\n            cv2.putText(vis_image, text, (x, y-5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 1)\n        \n        # Save the image if a save path is provided\n        if save_path:\n            try:\n                save_path.parent.mkdir(parents=True, exist_ok=True)\n                cv2.imwrite(str(save_path), vis_image)\n                console.print(f"[green]Visualized image saved to:[/green] {save_path}")\n            except Exception as e:\n                console.print(f"[bold red]Error saving image:[/bold red] {str(e)}")\n        \n        # Show the image if visualize is True\n        if visualize:\n            cv2.imshow("Checkbox Detection", vis_image)\n            console.print("[yellow]Press any key to close the visualization window[/yellow]")\n            cv2.waitKey(0)\n            cv2.destroyAllWindows()\n\nif __name__ == "__main__":\n    app()\n',
        },
        {
          path: "homevision-checkbox-detector-main/solution/common/form_cv/form_cv/__init__.py",
          content:
            '"""\nform-cv: A computer vision library for form processing and analysis\n"""\n\n__version__ = \'0.1.0\'\n\nfrom form_cv.form_cv.checkbox_checker import CheckboxChecker\n\n__all__ = [\'CheckboxChecker\']\n',
        },
        {
          path: "homevision-checkbox-detector-main/solution/common/form_cv/form_cv/checkbox_checker.py",
          content:
            'import cv2\nimport numpy as np\n\nclass CheckboxChecker:\n    """\n    A class to identify and check the state of checkboxes in form images.\n    """\n    image: np.ndarray\n    inv_binary_image: np.ndarray\n    contours: list[tuple[int, int, int, int]]\n    checkboxes: list[tuple[int, int, int, int]]\n\n    def __init__(self, image: np.ndarray):\n        """Initialize the CheckboxChecker"""\n        self.image = image\n        self.inv_binary_image = self.process_image(image)\n    \n    def process_image(self, image: np.ndarray) -> np.ndarray:\n        """Process the image to make it easier to detect checkboxes"""\n        # Convert to grayscale if needed\n        if len(image.shape) == 3:\n            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n        else:\n            gray = image.copy()\n        \n        # Apply threshold\n        _, thresh = cv2.threshold(gray.copy(), 127, 255, cv2.THRESH_BINARY_INV)        \n        \n        # Find contours\n        return thresh\n    \n    def is_checkbox_checked(self, roi: np.ndarray, threshold=0.30, padding_percent=10, noise_threshold=5) -> bool:\n        """\n        Determine if a checkbox is checked.\n        \n        Parameters:\n            roi: Region of interest\n            threshold: Minimum content percentage to significant\n            padding_percent: Percentage of padding to apply to the ROI\n            noise_threshold: Pixels threshold to be considered noise\n            \n        Returns:\n            bool: True if checkbox is checked, False otherwise\n        """\n        # TODO: Image must be a inverse binary image to work properly\n        # TODO: Add exception for non binary images\n\n        h, w = roi.shape\n    \n        # Get the corresponding percentage of the height and width that will be padding\n        pad_h = int(h * padding_percent / 100)\n        pad_w = int(w * padding_percent / 100)\n        \n        # Clip them to be at max size of the ROI\n        pad_h = min(pad_h, h // 3)\n        pad_w = min(pad_w, w // 3)\n        \n        # Get the ROI with padding already applied\n        inner_roi = roi[pad_h:h-pad_h, pad_w:w-pad_w]\n        \n        # In case the ROI is too small after padding just keep the original ROI\n        if inner_roi.shape[0] <= 0 or inner_roi.shape[1] <= 0:\n            inner_roi = roi\n        \n\n        filtered_roi = inner_roi.copy()\n        \n        # Find all connected components in the image\n        # connectivity=8 means we consider diagonal neighbors as connected\n        num_labels, labels, stats, _ = cv2.connectedComponentsWithStats(filtered_roi, connectivity=8)\n        \n\n        # For each component, we check if its area is smaller than our noise threshold\n        # If it is, we set all pixels belonging to that component to black\n        # Start from 1 to skip background\n        for i in range(1, num_labels):\n            if stats[i, cv2.CC_STAT_AREA] < noise_threshold:\n                filtered_roi[labels == i] = 0\n        \n        # Calculate the ratio of how much of the checkbox actually has content vs the total amount of pixels\n        # NOTE: The image is inverted, thus we have to check where pixels are greater than 0\n        inner_white_pixels = np.sum(filtered_roi > 0)\n        inner_total_pixels = filtered_roi.shape[0] * filtered_roi.shape[1]\n        inner_content_ratio = inner_white_pixels / inner_total_pixels if inner_total_pixels > 0 else 0\n        \n        # Check the size of the largest component\n        largest_comp_size = 0\n        if num_labels > 1:  # If we have components besides background\n            largest_comp_size = max(stats[1:, cv2.CC_STAT_AREA])\n        \n        # Calculate the complete ROI (without padding applied) content ratio\n        full_white_pixels = np.sum(roi > 0)\n        full_total_pixels = roi.shape[0] * roi.shape[1]\n        full_content_ratio = full_white_pixels / full_total_pixels if full_total_pixels > 0 else 0\n        \n        # Detection flags\n        has_content = inner_content_ratio > threshold and largest_comp_size >= noise_threshold * 2\n        has_center_content = False\n        has_line_pattern = False\n        has_cross_pattern = False\n        has_dot = False\n        \n\n        # Checkboxes have 5 main symbols to symbolize checked:\n        # X - the x symbol\n        # ✔ - the tick\n        # • - the dot\n        # ▪ - the square dot\n        # ■ - filled square\n        # The symbol found depends on what software was used to fill a certain PDF form\n\n\n        # ------ Dot / Square Dot Detection -------\n        # Dot detection has the following constraints\n        # Min content pixels: 5 px or 5%\n        # Max inner content pixels for it to be considered a dot: 30%\n        # This means that if a certain checkbox has more than 30% content pixels it will not be considered a dot.\n        # also this leaves the possibility for a filled out checkbox to not be considered a Dot.\n        # TODO: Add edge case for filled out checkbox\n\n        center_pad_h = int(h * 0.25)\n        center_pad_w = int(w * 0.25)\n        center_roi = filtered_roi\n        \n        # Creates a smaller ROI from the center of the filtered_roi\n        # Check if the filtered_roi is large enough to create a center region\n        if filtered_roi.shape[0] > 2 * center_pad_h and filtered_roi.shape[1] > 2 * center_pad_w:\n            center_h, center_w = filtered_roi.shape\n\n            # Extract the center region by cropping from all sides using the padding values\n            center_roi = filtered_roi[center_pad_h:center_h-center_pad_h, center_pad_w:center_w-center_pad_w]\n        \n        if center_roi.shape[0] > 0 and center_roi.shape[1] > 0:\n            center_white = np.sum(center_roi > 0)\n            center_total = center_roi.shape[0] * center_roi.shape[1]\n            center_ratio = center_white / center_total if center_total > 0 else 0\n            \n            # Only consider it true center content if its substantial (not just a few pixels)\n            min_center_pixels = max(5, center_total * 0.05)  # At least 5 pixels or 5% of center area\n            has_center_content = center_ratio > 0.2 and center_white >= min_center_pixels\n          \n            if has_center_content and center_ratio > 0.2 and inner_content_ratio < 0.3 and center_white >= min_center_pixels:\n                has_dot = True\n        \n        # ------ Checkmark / X Detection (and any other lines that may symbolize this) -------\n        if inner_content_ratio > 0.1 or (full_content_ratio > 0.15 and largest_comp_size > noise_threshold * 3):\n            \n            # Detect lines based on the edges of the checkbox (without taking into consideration what it may be a border)\n            edges = cv2.Canny(filtered_roi, 50, 150)\n            lines = cv2.HoughLinesP(edges, 1, np.pi/180, threshold=8, \n                                  minLineLength=min(filtered_roi.shape[1], filtered_roi.shape[0])/5, \n                                  maxLineGap=5)\n\n            if lines is not None and len(lines) > 0:\n                # Check if any lines are substantial (longer than noise)\n                substantial_lines = 0\n                angles = []\n                \n                for line in lines:\n                    x1, y1, x2, y2 = line[0]\n\n                    # Calculate the length of the line\n                    # sqrt((x2-x1)^2 + (y2-y1)^2) gives the straight-line distance between two points\n                    line_length = np.sqrt((x2-x1)**2 + (y2-y1)**2)\n                    \n                    # Only consider substantial lines\n                    if line_length >= noise_threshold:\n                        substantial_lines += 1\n                        # Calculate the angle of the line in degrees\n                        if x2 != x1:  # Avoid division by zero\n                            \n                            # np.arctan2 angle in radians between the positive x-axis and the point\n                            # np.degrees converts from radians to degrees\n                            # % 180 ensures the angle is between 0 and 180 degrees (we dont care about direction)\n                            angle = np.degrees(np.arctan2(y2-y1, x2-x1)) % 180\n                            angles.append(angle)\n                \n                if substantial_lines > 0:\n                    # Check for diagonal lines\n                    diagonal_lines = sum(1 for angle in angles if (30 <= angle <= 60) or (120 <= angle <= 150))\n                    \n                    # Could be a checkmark\n                    has_line_pattern = diagonal_lines >= 1\n                    \n                    # Check for cross\n                    left_diagonal = sum(1 for angle in angles if 30 <= angle <= 60)\n                    right_diagonal = sum(1 for angle in angles if 120 <= angle <= 150)\n\n                    # If there are multiple lines and they cross at ~90 degrees\n                    # then we can assume cross pattern\n                    has_cross_pattern = left_diagonal >= 1 and right_diagonal >= 1\n        \n        # Each of these OR conditions end up being necessary in this implementation\n        # Ideally they would be reduced to other variables that allow for independent verification\n        # of the conditions\n        is_checked = (has_content or has_center_content or has_line_pattern or \n                      has_cross_pattern or has_dot) and largest_comp_size >= noise_threshold\n        \n        return is_checked\n        \n    def detect_checkboxes(self, min_size=20, max_size=50) -> list[tuple[int, int, int, int]]:\n        """\n        Detect checkboxes in the given image.\n        \n        Parameters:\n            image: Input image\n            min_size: Minimum size of checkbox to detect\n            max_size: Maximum size of checkbox to detect\n            \n        Returns:\n            list: List of tuples containing checkbox coordinates (x, y, w, h) and contour\n        """\n        # Find contours\n        contours, _ = cv2.findContours(self.inv_binary_image, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n\n        checkbox_candidates = []\n        \n        for contour in contours:\n          x, y, w, h = cv2.boundingRect(contour)\n          \n          if (min_size <= w <= max_size and \n              min_size <= h <= max_size):\n              \n              aspect_ratio = float(w) / h\n              \n              if 0.8 <= aspect_ratio <= 1.2:\n                  checkbox_candidates.append((x, y, w, h))\n\n        self.checkboxes = checkbox_candidates\n        return checkbox_candidates\n    \n    def get_checkbox_states(self, threshold=0.30, padding_percent=10) -> dict[int, tuple[int, int, int, int, bool]]:\n        """\n        Determine the state of each checkbox.\n        \n        Parameters:\n            image: Input image\n            checkboxes: List of checkbox coordinates from detect_checkboxes\n            threshold: Threshold for checkbox content\n            padding_percent: Padding percentage\n            \n        Returns:\n            dict: Dictionary mapping checkbox coordinates to boolean states\n        """\n        checkbox_states = {}\n        \n        for i, (x, y, w, h) in enumerate(self.checkboxes):\n            # Extract the region of interest\n            roi = self.inv_binary_image[y:y+h, x:x+w]\n            # Check if the checkbox is checked\n            is_checked = self.is_checkbox_checked(roi, threshold, padding_percent)\n            \n            # Store the result\n            checkbox_states[i] = (x, y, w, h, is_checked)\n        \n        return checkbox_states\n',
        },
        {
          path: "homevision-checkbox-detector-main/solution/common/form_cv/setup.py",
          content:
            'from setuptools import setup, find_packages\n\nsetup(\n    name="form-cv",\n    version="0.1.0",\n    packages=find_packages(),\n    install_requires=[\n        "opencv-python>=4.5.0",\n        "numpy>=1.19.0",\n    ],\n    author="Pedro",\n    author_email="pebustos.135@gmail.com",\n    description="A computer vision library for form processing and analysis",\n    long_description=open("README.md").read(),\n    long_description_content_type="text/markdown",\n    url="https://github.com/kildall",\n    classifiers=[\n        "Programming Language :: Python :: 3",\n        "License :: OSI Approved :: MIT License",\n        "Operating System :: OS Independent",\n    ],\n    python_requires=">=3.10",\n)\n',
        },
        {
          path: "homevision-checkbox-detector-main/solution/frontend/app/layout.tsx",
          content:
            "import type { Metadata } from 'next'\nimport { Inter } from 'next/font/google'\nimport './globals.css'\n\nconst inter = Inter({ subsets: ['latin'] })\n\nexport const metadata: Metadata = {\n  title: 'Form CV Checkbox Detection',\n  description: 'Detect and analyze checkboxes in form images',\n}\n\nexport default function RootLayout({\n  children,\n}: {\n  children: React.ReactNode\n}) {\n  return (\n    <html lang=\"en\">\n      <body className={inter.className}>\n        <main className=\"min-h-screen flex flex-col\">\n          <header className=\"bg-primary text-primary-foreground p-4\">\n            <div className=\"container mx-auto\">\n              <h1 className=\"text-2xl font-bold\">Form Computer Vision Tool</h1>\n            </div>\n          </header>\n          <div className=\"flex-1 container mx-auto py-6\">\n            {children}\n          </div>\n        </main>\n      </body>\n    </html>\n  )\n} ",
        },
        {
          path: "homevision-checkbox-detector-main/solution/frontend/app/page.tsx",
          content:
            '"use client"\n\nimport { useState } from \'react\'\nimport { Tabs, TabsContent, TabsList, TabsTrigger } from \'@/components/ui/tabs\'\nimport { Card, CardContent, CardDescription, CardHeader, CardTitle } from \'@/components/ui/card\'\nimport UploadForm from \'@/components/upload-form\'\nimport ResultsList from \'@/components/results-list\'\n\nexport default function Home() {\n  const [_, setActiveTab] = useState("upload")\n  \n  return (\n    <div className="flex flex-col space-y-8">      \n      <Tabs defaultValue="upload" className="w-full" onValueChange={setActiveTab}>\n        <TabsList className="grid w-full grid-cols-2">\n          <TabsTrigger value="upload">Upload Image</TabsTrigger>\n          <TabsTrigger value="history">History</TabsTrigger>\n        </TabsList>\n        \n        <TabsContent value="upload" className="mt-6">\n          <Card>\n            <CardHeader>\n              <CardTitle>Upload an image</CardTitle>\n              <CardDescription>\n                Upload an image containing a form to detect and analyze it.\n              </CardDescription>\n            </CardHeader>\n            <CardContent>\n              <UploadForm onSuccess={() => setActiveTab("history")} />\n            </CardContent>\n          </Card>\n        </TabsContent>\n        \n        <TabsContent value="history" className="mt-6">\n          <Card>\n            <CardHeader>\n              <CardTitle>Detection History</CardTitle>\n              <CardDescription>\n                View previous form detection results.\n              </CardDescription>\n            </CardHeader>\n            <CardContent>\n              <ResultsList />\n            </CardContent>\n          </Card>\n        </TabsContent>\n      </Tabs>\n    </div>\n  )\n} ',
        },
        {
          path: "homevision-checkbox-detector-main/solution/frontend/components/detection-result-view.tsx",
          content:
            '"use client"\n\nimport { Button } from \'@/components/ui/button\'\nimport { DetectionResult } from \'@/lib/api\'\nimport { formatDistanceToNow } from \'date-fns\'\nimport { ArrowLeftIcon } from \'lucide-react\'\nimport Image from \'next/image\'\n\ninterface DetectionResultViewProps {\n  result: DetectionResult\n  onReset?: () => void\n}\n\nexport default function DetectionResultView({ result, onReset }: DetectionResultViewProps) {\n  const { filename, timestamp, min_size, max_size, threshold, padding, result: checkboxes, visualization } = result\n  \n  // Count checked/unchecked boxes\n  const checkboxStats = Object.values(checkboxes).reduce(\n    (acc, checkbox) => {\n      if (checkbox.checked) {\n        acc.checked += 1\n      } else {\n        acc.unchecked += 1\n      }\n      return acc\n    },\n    { checked: 0, unchecked: 0, total: Object.keys(checkboxes).length }\n  )\n  \n  const timeAgo = formatDistanceToNow(new Date(timestamp), { addSuffix: true })\n  \n  return (\n    <div className="space-y-6">\n      <div className="flex items-center justify-between">\n        <div>\n          <h3 className="text-lg font-medium">{filename}</h3>\n          <p className="text-sm text-muted-foreground">Processed {timeAgo}</p>\n        </div>\n        {onReset && (\n          <Button variant="outline" onClick={onReset} size="sm">\n            <ArrowLeftIcon className="h-4 w-4 mr-2" />\n            Back\n          </Button>\n        )}\n      </div>\n      \n      {visualization && (\n        <div className="relative aspect-video rounded-lg overflow-hidden border border-muted">\n          <Image\n            src={`data:image/png;base64,${visualization}`}\n            alt="Checkbox detection visualization"\n            fill\n            style={{ objectFit: \'contain\' }}\n          />\n        </div>\n      )}\n      \n      <div className="grid grid-cols-1 md:grid-cols-3 gap-4">\n        <div className="bg-primary/5 rounded-lg p-4">\n          <div className="text-sm text-muted-foreground">Total Checkboxes</div>\n          <div className="text-3xl font-bold">{checkboxStats.total}</div>\n        </div>\n        <div className="bg-green-100 rounded-lg p-4 dark:bg-green-900/20">\n          <div className="text-sm text-muted-foreground">Checked</div>\n          <div className="text-3xl font-bold text-green-600 dark:text-green-400">{checkboxStats.checked}</div>\n        </div>\n        <div className="bg-red-100 rounded-lg p-4 dark:bg-red-900/20">\n          <div className="text-sm text-muted-foreground">Unchecked</div>\n          <div className="text-3xl font-bold text-red-600 dark:text-red-400">{checkboxStats.unchecked}</div>\n        </div>\n      </div>\n      \n      <div className="bg-muted/30 rounded-lg p-4">\n        <h4 className="text-sm font-medium mb-2">Detection Parameters</h4>\n        <div className="grid grid-cols-2 md:grid-cols-4 gap-4 text-sm">\n          <div>\n            <div className="text-muted-foreground">Min Size</div>\n            <div>{min_size}px</div>\n          </div>\n          <div>\n            <div className="text-muted-foreground">Max Size</div>\n            <div>{max_size}px</div>\n          </div>\n          <div>\n            <div className="text-muted-foreground">Threshold</div>\n            <div>{threshold}</div>\n          </div>\n          <div>\n            <div className="text-muted-foreground">Padding</div>\n            <div>{padding}%</div>\n          </div>\n        </div>\n      </div>\n      \n      <div className="space-y-2">\n        <h4 className="text-sm font-medium">Checkbox Details</h4>\n        <div className="max-h-96 overflow-y-auto border rounded-lg">\n          <table className="w-full text-sm">\n            <thead>\n              <tr className="border-b bg-muted/50">\n                <th className="text-left py-2 px-4 font-medium">ID</th>\n                <th className="text-left py-2 px-4 font-medium">Position</th>\n                <th className="text-left py-2 px-4 font-medium">Size</th>\n                <th className="text-left py-2 px-4 font-medium">Status</th>\n              </tr>\n            </thead>\n            <tbody>\n              {Object.entries(checkboxes).map(([id, checkbox]) => (\n                <tr key={id} className="border-b last:border-0 hover:bg-muted/30">\n                  <td className="py-2 px-4">{id}</td>\n                  <td className="py-2 px-4">({checkbox.position.x}, {checkbox.position.y})</td>\n                  <td className="py-2 px-4">{checkbox.size.width}×{checkbox.size.height}</td>\n                  <td className="py-2 px-4">\n                    <span className={`inline-flex items-center px-2 py-1 rounded text-xs font-medium\n                      ${checkbox.checked ? \'bg-green-100 text-green-800 dark:bg-green-900/30 dark:text-green-400\' : \n                      \'bg-red-100 text-red-800 dark:bg-red-900/30 dark:text-red-400\'}`}>\n                      {checkbox.checked ? \'Checked\' : \'Unchecked\'}\n                    </span>\n                  </td>\n                </tr>\n              ))}\n            </tbody>\n          </table>\n        </div>\n      </div>\n    </div>\n  )\n} ',
        },
        {
          path: "homevision-checkbox-detector-main/solution/frontend/components/results-list.tsx",
          content:
            '"use client"\n\nimport { useEffect, useState } from \'react\'\nimport { getDetectionResults, DetectionResult } from \'@/lib/api\'\nimport { formatDistance, format } from \'date-fns\'\nimport { FileIcon, ChevronRightIcon, RefreshCwIcon } from \'lucide-react\'\nimport { Button } from \'@/components/ui/button\'\nimport DetectionResultView from \'./detection-result-view\'\n\nexport default function ResultsList() {\n  const [results, setResults] = useState<DetectionResult[]>([])\n  const [selectedResult, setSelectedResult] = useState<DetectionResult | null>(null)\n  const [loading, setLoading] = useState(true)\n  const [error, setError] = useState<string | null>(null)\n  \n  const fetchResults = async () => {\n    setLoading(true)\n    setError(null)\n    \n    try {\n      const data = await getDetectionResults()\n      setResults(data)\n    } catch (err) {\n      console.error(\'Failed to fetch results:\', err)\n      setError(\'Failed to load results. Please try again.\')\n    } finally {\n      setLoading(false)\n    }\n  }\n  \n  useEffect(() => {\n    fetchResults()\n  }, [])\n  \n  const handleSelectResult = (result: DetectionResult) => {\n    setSelectedResult(result)\n  }\n  \n  const handleBack = () => {\n    setSelectedResult(null)\n  }\n  \n  if (selectedResult) {\n    return <DetectionResultView result={selectedResult} onReset={handleBack} />\n  }\n  \n  return (\n    <div className="space-y-4">\n      <div className="flex justify-between items-center">\n        <h3 className="text-lg font-medium">Previous Results</h3>\n        <Button variant="outline" size="sm" onClick={fetchResults} disabled={loading}>\n          <RefreshCwIcon className={`h-4 w-4 mr-2 ${loading ? \'animate-spin\' : \'\'}`} />\n          Refresh\n        </Button>\n      </div>\n      \n      {loading && (\n        <div className="flex justify-center py-8">\n          <RefreshCwIcon className="h-8 w-8 animate-spin text-muted-foreground" />\n        </div>\n      )}\n      \n      {error && (\n        <div className="p-4 bg-destructive/10 text-destructive rounded-lg">\n          {error}\n        </div>\n      )}\n      \n      {!loading && results.length === 0 && (\n        <div className="text-center py-8 text-muted-foreground">\n          <p>No detection results found</p>\n          <p className="text-sm">Upload an image to see results here</p>\n        </div>\n      )}\n      \n      <div className="space-y-2">\n        {results.map((result) => (\n          <div \n            key={result.id} \n            className="border rounded-md hover:bg-muted/50 transition-colors cursor-pointer"\n            onClick={() => handleSelectResult(result)}\n          >\n            <div className="p-4 flex items-center justify-between">\n              <div className="flex items-center">\n                <div className="bg-primary/10 rounded-full p-2 mr-3">\n                  <FileIcon className="h-5 w-5 text-primary" />\n                </div>\n                <div>\n                  <h4 className="font-medium">{result.filename}</h4>\n                  <p className="text-sm text-muted-foreground">\n                    {new Date(result.timestamp).toLocaleString()} | \n                    {Object.keys(result.result).length} checkboxes\n                  </p>\n                </div>\n              </div>\n              <ChevronRightIcon className="h-5 w-5 text-muted-foreground" />\n            </div>\n          </div>\n        ))}\n      </div>\n    </div>\n  )\n} ',
        },
        {
          path: "homevision-checkbox-detector-main/solution/frontend/components/ui/button.tsx",
          content:
            'import * as React from "react"\nimport { Slot } from "@radix-ui/react-slot"\nimport { cva, type VariantProps } from "class-variance-authority"\n\nimport { cn } from "@/lib/utils"\n\nconst buttonVariants = cva(\n  "inline-flex items-center justify-center whitespace-nowrap rounded-md text-sm font-medium ring-offset-background transition-colors focus-visible:outline-none focus-visible:ring-2 focus-visible:ring-ring focus-visible:ring-offset-2 disabled:pointer-events-none disabled:opacity-50",\n  {\n    variants: {\n      variant: {\n        default: "bg-primary text-primary-foreground hover:bg-primary/90",\n        destructive:\n          "bg-destructive text-destructive-foreground hover:bg-destructive/90",\n        outline:\n          "border border-input bg-background hover:bg-accent hover:text-accent-foreground",\n        secondary:\n          "bg-secondary text-secondary-foreground hover:bg-secondary/80",\n        ghost: "hover:bg-accent hover:text-accent-foreground",\n        link: "text-primary underline-offset-4 hover:underline",\n      },\n      size: {\n        default: "h-10 px-4 py-2",\n        sm: "h-9 rounded-md px-3",\n        lg: "h-11 rounded-md px-8",\n        icon: "h-10 w-10",\n      },\n    },\n    defaultVariants: {\n      variant: "default",\n      size: "default",\n    },\n  }\n)\n\nexport interface ButtonProps\n  extends React.ButtonHTMLAttributes<HTMLButtonElement>,\n    VariantProps<typeof buttonVariants> {\n  asChild?: boolean\n}\n\nconst Button = React.forwardRef<HTMLButtonElement, ButtonProps>(\n  ({ className, variant, size, asChild = false, ...props }, ref) => {\n    const Comp = asChild ? Slot : "button"\n    return (\n      <Comp\n        className={cn(buttonVariants({ variant, size, className }))}\n        ref={ref}\n        {...props}\n      />\n    )\n  }\n)\nButton.displayName = "Button"\n\nexport { Button, buttonVariants } ',
        },
        {
          path: "homevision-checkbox-detector-main/solution/frontend/components/ui/card.tsx",
          content:
            'import * as React from "react"\n\nimport { cn } from "@/lib/utils"\n\nconst Card = React.forwardRef<\n  HTMLDivElement,\n  React.HTMLAttributes<HTMLDivElement>\n>(({ className, ...props }, ref) => (\n  <div\n    ref={ref}\n    className={cn(\n      "rounded-lg border bg-card text-card-foreground shadow-sm",\n      className\n    )}\n    {...props}\n  />\n))\nCard.displayName = "Card"\n\nconst CardHeader = React.forwardRef<\n  HTMLDivElement,\n  React.HTMLAttributes<HTMLDivElement>\n>(({ className, ...props }, ref) => (\n  <div\n    ref={ref}\n    className={cn("flex flex-col space-y-1.5 p-6", className)}\n    {...props}\n  />\n))\nCardHeader.displayName = "CardHeader"\n\nconst CardTitle = React.forwardRef<\n  HTMLParagraphElement,\n  React.HTMLAttributes<HTMLHeadingElement>\n>(({ className, ...props }, ref) => (\n  <h3\n    ref={ref}\n    className={cn(\n      "text-2xl font-semibold leading-none tracking-tight",\n      className\n    )}\n    {...props}\n  />\n))\nCardTitle.displayName = "CardTitle"\n\nconst CardDescription = React.forwardRef<\n  HTMLParagraphElement,\n  React.HTMLAttributes<HTMLParagraphElement>\n>(({ className, ...props }, ref) => (\n  <p\n    ref={ref}\n    className={cn("text-sm text-muted-foreground", className)}\n    {...props}\n  />\n))\nCardDescription.displayName = "CardDescription"\n\nconst CardContent = React.forwardRef<\n  HTMLDivElement,\n  React.HTMLAttributes<HTMLDivElement>\n>(({ className, ...props }, ref) => (\n  <div ref={ref} className={cn("p-6 pt-0", className)} {...props} />\n))\nCardContent.displayName = "CardContent"\n\nconst CardFooter = React.forwardRef<\n  HTMLDivElement,\n  React.HTMLAttributes<HTMLDivElement>\n>(({ className, ...props }, ref) => (\n  <div\n    ref={ref}\n    className={cn("flex items-center p-6 pt-0", className)}\n    {...props}\n  />\n))\nCardFooter.displayName = "CardFooter"\n\nexport { Card, CardHeader, CardFooter, CardTitle, CardDescription, CardContent } ',
        },
        {
          path: "homevision-checkbox-detector-main/solution/frontend/components/ui/tabs.tsx",
          content:
            'import * as React from "react"\nimport * as TabsPrimitive from "@radix-ui/react-tabs"\n\nimport { cn } from "@/lib/utils"\n\nconst Tabs = TabsPrimitive.Root\n\nconst TabsList = React.forwardRef<\n  React.ElementRef<typeof TabsPrimitive.List>,\n  React.ComponentPropsWithoutRef<typeof TabsPrimitive.List>\n>(({ className, ...props }, ref) => (\n  <TabsPrimitive.List\n    ref={ref}\n    className={cn(\n      "inline-flex h-10 items-center justify-center rounded-md bg-muted p-1 text-muted-foreground",\n      className\n    )}\n    {...props}\n  />\n))\nTabsList.displayName = TabsPrimitive.List.displayName\n\nconst TabsTrigger = React.forwardRef<\n  React.ElementRef<typeof TabsPrimitive.Trigger>,\n  React.ComponentPropsWithoutRef<typeof TabsPrimitive.Trigger>\n>(({ className, ...props }, ref) => (\n  <TabsPrimitive.Trigger\n    ref={ref}\n    className={cn(\n      "inline-flex items-center justify-center whitespace-nowrap rounded-sm px-3 py-1.5 text-sm font-medium ring-offset-background transition-all focus-visible:outline-none focus-visible:ring-2 focus-visible:ring-ring focus-visible:ring-offset-2 disabled:pointer-events-none disabled:opacity-50 data-[state=active]:bg-background data-[state=active]:text-foreground data-[state=active]:shadow-sm",\n      className\n    )}\n    {...props}\n  />\n))\nTabsTrigger.displayName = TabsPrimitive.Trigger.displayName\n\nconst TabsContent = React.forwardRef<\n  React.ElementRef<typeof TabsPrimitive.Content>,\n  React.ComponentPropsWithoutRef<typeof TabsPrimitive.Content>\n>(({ className, ...props }, ref) => (\n  <TabsPrimitive.Content\n    ref={ref}\n    className={cn(\n      "mt-2 ring-offset-background focus-visible:outline-none focus-visible:ring-2 focus-visible:ring-ring focus-visible:ring-offset-2",\n      className\n    )}\n    {...props}\n  />\n))\nTabsContent.displayName = TabsPrimitive.Content.displayName\n\nexport { Tabs, TabsList, TabsTrigger, TabsContent } ',
        },
        {
          path: "homevision-checkbox-detector-main/solution/frontend/components/upload-form.tsx",
          content:
            '"use client"\n\nimport { useState, useCallback } from \'react\'\nimport { useDropzone } from \'react-dropzone\'\nimport { Button } from \'@/components/ui/button\'\nimport { detectCheckboxes, DetectionResult } from \'@/lib/api\'\nimport Image from \'next/image\'\nimport { ArrowUpIcon, CheckIcon, XIcon, Loader2Icon, SlidersIcon } from \'lucide-react\'\nimport DetectionResultView from \'@/components/detection-result-view\'\n\ninterface UploadFormProps {\n  onSuccess?: () => void\n}\n\nconst supportedFormats = [\'.png\', \'.jpg\', \'.jpeg\', \'.bmp\', \'.gif\', \'.tiff\', \'.webp\']\nconst supportedFormatsString = supportedFormats.join(\', \').toUpperCase().replaceAll(\'.\', \'\')\n\nexport default function UploadForm({ onSuccess }: UploadFormProps) {\n  const [file, setFile] = useState<File | null>(null)\n  const [preview, setPreview] = useState<string | null>(null)\n  const [loading, setLoading] = useState(false)\n  const [error, setError] = useState<string | null>(null)\n  const [result, setResult] = useState<DetectionResult | null>(null)\n  \n  // Parameters\n  const [minSize, setMinSize] = useState<number>(20)\n  const [maxSize, setMaxSize] = useState<number>(50)\n  const [threshold, setThreshold] = useState<number>(0.3)\n  const [padding, setPadding] = useState<number>(10)\n  \n  const onDrop = useCallback((acceptedFiles: File[]) => {\n    if (acceptedFiles.length === 0) return\n    \n    const file = acceptedFiles[0]\n    setFile(file)\n    \n    // Create preview\n    const reader = new FileReader()\n    reader.onload = () => {\n      setPreview(reader.result as string)\n    }\n    reader.readAsDataURL(file)\n    \n    // Reset states\n    setError(null)\n    setResult(null)\n  }, [])\n  \n  const { getRootProps, getInputProps, isDragActive } = useDropzone({\n    onDrop,\n    accept: {\n      \'image/*\': supportedFormats\n    },\n    maxFiles: 1,\n    multiple: false\n  })\n  \n  const handleSubmit = async () => {\n    if (!file) {\n      setError(\'Please select an image file\')\n      return\n    }\n    \n    setLoading(true)\n    setError(null)\n    \n    try {\n      const result = await detectCheckboxes(file, {\n        min_size: minSize,\n        max_size: maxSize,\n        threshold: threshold,\n        padding: padding\n      })\n      setResult(result)\n      if (onSuccess) {\n        onSuccess()\n      }\n    } catch (err) {\n      console.error(\'Error detecting checkboxes:\', err)\n      setError(\'Failed to process image. Please try again.\')\n    } finally {\n      setLoading(false)\n    }\n  }\n  \n  const handleReset = () => {\n    setFile(null)\n    setPreview(null)\n    setResult(null)\n    setError(null)\n  }\n  \n  return (\n    <div className="space-y-6">\n      {!file && !result && (\n        <div \n          {...getRootProps()} \n          className={`border-2 border-dashed rounded-lg p-12 text-center cursor-pointer hover:bg-muted/50 transition-colors\n            ${isDragActive ? \'border-primary bg-primary/5\' : \'border-muted\'}`}\n          onClick={() => document.getElementById(\'file-upload-input\')?.click()}\n        >\n          <input {...getInputProps()} id="file-upload-input" />\n          <div className="flex flex-col items-center justify-center gap-4">\n            <div className="rounded-full bg-primary/10 p-4">\n              <ArrowUpIcon className="h-8 w-8 text-primary" />\n            </div>\n            <div>\n              <p className="text-base font-medium">Drag and drop or click to upload</p>\n              <p className="text-sm text-muted-foreground">\n                Supported formats: {supportedFormatsString}\n              </p>\n            </div>\n            <Button \n              type="button" \n              variant="outline" \n              size="sm"\n              onClick={(e) => {\n                e.stopPropagation();\n                document.getElementById(\'file-upload-input\')?.click();\n              }}\n            >\n              Browse Files\n            </Button>\n          </div>\n        </div>\n      )}\n      \n      {preview && !result && (\n        <div className="space-y-6">\n          <div className="relative aspect-video rounded-lg overflow-hidden border border-muted">\n            <Image\n              src={preview}\n              alt="Preview"\n              fill\n              style={{ objectFit: \'contain\' }}\n            />\n            <Button\n              variant="secondary"\n              size="sm"\n              className="absolute top-2 right-2"\n              onClick={handleReset}\n            >\n              <XIcon className="h-4 w-4 mr-1" />\n              Clear\n            </Button>\n          </div>\n\n          {/* Parameters section */}\n          <div className="bg-muted/30 rounded-lg p-4 space-y-4">\n            <div className="flex items-center gap-2">\n              <SlidersIcon className="h-4 w-4 text-primary" />\n              <h3 className="font-medium">Detection Parameters</h3>\n            </div>\n            \n            <div className="grid grid-cols-1 md:grid-cols-2 gap-4">\n              <div className="space-y-2">\n                <div className="flex justify-between">\n                  <label htmlFor="min-size" className="text-sm font-medium">Min Size (px)</label>\n                  <span className="text-sm text-muted-foreground">{minSize}</span>\n                </div>\n                <input \n                  id="min-size"\n                  type="range" \n                  min="5" \n                  max="100" \n                  value={minSize} \n                  onChange={(e) => setMinSize(Number(e.target.value))}\n                  className="w-full accent-primary"\n                />\n                <p className="text-xs text-muted-foreground">Minimum size of checkbox to detect</p>\n              </div>\n              \n              <div className="space-y-2">\n                <div className="flex justify-between">\n                  <label htmlFor="max-size" className="text-sm font-medium">Max Size (px)</label>\n                  <span className="text-sm text-muted-foreground">{maxSize}</span>\n                </div>\n                <input \n                  id="max-size"\n                  type="range" \n                  min="20" \n                  max="200" \n                  value={maxSize} \n                  onChange={(e) => setMaxSize(Number(e.target.value))}\n                  className="w-full accent-primary"\n                />\n                <p className="text-xs text-muted-foreground">Maximum size of checkbox to detect</p>\n              </div>\n              \n              <div className="space-y-2">\n                <div className="flex justify-between">\n                  <label htmlFor="threshold" className="text-sm font-medium">Threshold</label>\n                  <span className="text-sm text-muted-foreground">{threshold.toFixed(2)}</span>\n                </div>\n                <input \n                  id="threshold"\n                  type="range" \n                  min="0" \n                  max="1" \n                  step="0.05"\n                  value={threshold} \n                  onChange={(e) => setThreshold(Number(e.target.value))}\n                  className="w-full accent-primary"\n                />\n                <p className="text-xs text-muted-foreground">Threshold for determining if a checkbox is checked</p>\n              </div>\n              \n              <div className="space-y-2">\n                <div className="flex justify-between">\n                  <label htmlFor="padding" className="text-sm font-medium">Padding (%)</label>\n                  <span className="text-sm text-muted-foreground">{padding}</span>\n                </div>\n                <input \n                  id="padding"\n                  type="range" \n                  min="0" \n                  max="50" \n                  value={padding} \n                  onChange={(e) => setPadding(Number(e.target.value))}\n                  className="w-full accent-primary"\n                />\n                <p className="text-xs text-muted-foreground">Padding percentage for the checkbox ROI</p>\n              </div>\n            </div>\n          </div>\n          \n          <div className="flex justify-end gap-4">\n            <Button\n              variant="outline"\n              onClick={handleReset}\n              disabled={loading}\n            >\n              Cancel\n            </Button>\n            <Button\n              onClick={handleSubmit}\n              disabled={loading}\n              className="flex items-center gap-2"\n            >\n              {loading ? (\n                <>\n                  <Loader2Icon className="h-4 w-4 animate-spin" />\n                  Processing...\n                </>\n              ) : (\n                <>\n                  <CheckIcon className="h-4 w-4" />\n                  Detect Checkboxes\n                </>\n              )}\n            </Button>\n          </div>\n        </div>\n      )}\n      \n      {error && (\n        <div className="p-4 bg-destructive/10 text-destructive rounded-lg">\n          {error}\n        </div>\n      )}\n      \n      {result && (\n        <DetectionResultView result={result} onReset={handleReset} />\n      )}\n    </div>\n  )\n} ',
        },
        {
          path: "homevision-checkbox-detector-main/solution/frontend/lib/api.ts",
          content:
            "import axios from 'axios';\n\nconst API_URL = process.env.NEXT_PUBLIC_API_URL || 'http://localhost:5000/api';\n\nconst api = axios.create({\n  baseURL: API_URL\n});\n\nexport interface CheckboxPosition {\n  x: number;\n  y: number;\n}\n\nexport interface CheckboxSize {\n  width: number;\n  height: number;\n}\n\nexport interface CheckboxResult {\n  position: CheckboxPosition;\n  size: CheckboxSize;\n  checked: boolean;\n}\n\nexport interface DetectionResult {\n  id: string;\n  filename: string;\n  timestamp: string;\n  min_size: number;\n  max_size: number;\n  threshold: number;\n  padding: number;\n  result: Record<string, CheckboxResult>;\n  visualization?: string;\n  checkbox_count?: number;\n}\n\nexport async function detectCheckboxes(\n  image: File,\n  params: {\n    min_size?: number;\n    max_size?: number;\n    threshold?: number;\n    padding?: number;\n  } = {}\n): Promise<DetectionResult> {\n  const formData = new FormData();\n  formData.append('image', image);\n  \n  if (params.min_size) formData.append('min_size', params.min_size.toString());\n  if (params.max_size) formData.append('max_size', params.max_size.toString());\n  if (params.threshold) formData.append('threshold', params.threshold.toString());\n  if (params.padding) formData.append('padding', params.padding.toString());\n  \n  const response = await api.post<DetectionResult>('/detect', formData, {\n    headers: {\n      'Content-Type': 'multipart/form-data'\n    }\n  });\n  \n  return response.data;\n}\n\nexport async function getDetectionResults(): Promise<DetectionResult[]> {\n  const response = await api.get<DetectionResult[]>('/results');\n  return response.data;\n}\n\nexport async function getDetectionResult(id: string): Promise<DetectionResult> {\n  const response = await api.get<DetectionResult>(`/results/${id}`);\n  return response.data;\n} ",
        },
        {
          path: "homevision-checkbox-detector-main/solution/frontend/lib/utils.ts",
          content:
            'import { type ClassValue, clsx } from "clsx"\nimport { twMerge } from "tailwind-merge"\n\nexport function cn(...inputs: ClassValue[]) {\n  return twMerge(clsx(inputs))\n} ',
        },
        {
          path: "homevision-checkbox-detector-main/solution/frontend/next-env.d.ts",
          content:
            '/// <reference types="next" />\n/// <reference types="next/image-types/global" />\n\n// NOTE: This file should not be edited\n// see https://nextjs.org/docs/app/api-reference/config/typescript for more information.\n',
        },
        {
          path: "homevision-checkbox-detector-main/solution/frontend/next.config.js",
          content:
            "/** @type {import('next').NextConfig} */\nconst nextConfig = {\n  reactStrictMode: true,\n  images: {\n    domains: ['localhost'],\n  },\n}\n\nmodule.exports = nextConfig ",
        },
        {
          path: "homevision-checkbox-detector-main/solution/frontend/postcss.config.js",
          content:
            "module.exports = {\n  plugins: {\n    tailwindcss: {},\n    autoprefixer: {},\n  },\n} ",
        },
        {
          path: "homevision-checkbox-detector-main/solution/frontend/tailwind.config.js",
          content:
            '/** @type {import(\'tailwindcss\').Config} */\nmodule.exports = {\n  darkMode: ["class"],\n  content: [\n    \'./pages/**/*.{ts,tsx}\',\n    \'./components/**/*.{ts,tsx}\',\n    \'./app/**/*.{ts,tsx}\',\n    \'./src/**/*.{ts,tsx}\',\n  ],\n  theme: {\n    container: {\n      center: true,\n      padding: "2rem",\n      screens: {\n        "2xl": "1400px",\n      },\n    },\n    extend: {\n      colors: {\n        border: "hsl(var(--border))",\n        input: "hsl(var(--input))",\n        ring: "hsl(var(--ring))",\n        background: "hsl(var(--background))",\n        foreground: "hsl(var(--foreground))",\n        primary: {\n          DEFAULT: "hsl(var(--primary))",\n          foreground: "hsl(var(--primary-foreground))",\n        },\n        secondary: {\n          DEFAULT: "hsl(var(--secondary))",\n          foreground: "hsl(var(--secondary-foreground))",\n        },\n        destructive: {\n          DEFAULT: "hsl(var(--destructive))",\n          foreground: "hsl(var(--destructive-foreground))",\n        },\n        muted: {\n          DEFAULT: "hsl(var(--muted))",\n          foreground: "hsl(var(--muted-foreground))",\n        },\n        accent: {\n          DEFAULT: "hsl(var(--accent))",\n          foreground: "hsl(var(--accent-foreground))",\n        },\n        popover: {\n          DEFAULT: "hsl(var(--popover))",\n          foreground: "hsl(var(--popover-foreground))",\n        },\n        card: {\n          DEFAULT: "hsl(var(--card))",\n          foreground: "hsl(var(--card-foreground))",\n        },\n      },\n      borderRadius: {\n        lg: "var(--radius)",\n        md: "calc(var(--radius) - 2px)",\n        sm: "calc(var(--radius) - 4px)",\n      },\n      keyframes: {\n        "accordion-down": {\n          from: { height: 0 },\n          to: { height: "var(--radix-accordion-content-height)" },\n        },\n        "accordion-up": {\n          from: { height: "var(--radix-accordion-content-height)" },\n          to: { height: 0 },\n        },\n      },\n      animation: {\n        "accordion-down": "accordion-down 0.2s ease-out",\n        "accordion-up": "accordion-up 0.2s ease-out",\n      },\n    },\n  },\n  plugins: [require("tailwindcss-animate")],\n} ',
        },
      ],
      docs: "# Homevision Backend Engineer Take-Home Challenge\n\n## Structure\n\n- `concept` folder contains the preliminary thought process used to come up with a solution\n- `solution` folder contains a number of subfolder of a more refined answer:\n  - `api` / `frontend` contain a full stack application that makes use of the library\n  - `cli` provides a command line interface for interfacing with the library\n  - `common` contains the main computer vision logic of the applicaiton\n\n## How to run\n\n### Parameters\n\nSince the library created for this challenge takes some parameters, the following are the correct ones for the provided sample image:\n\n- Minimum size: 22\n- Maximum size: 28\n\nAll other parameters can be left default and it will work correctly.\n\nAs for other images, I recommend playing with settings inside the web version of the tool, but as a reference\nwe should consider the amount of \"zoom\" an image contains, if it's too zoomed in, then the checkbox will be larger\nand if it's zoomed out, the the inverse will be true.\n\n### Common Library\n\nSee the [Form Computer Vision Library README](solution/common/form_cv/README.md) for details on the core library.\n\n### API Server\n\nSee the [API Server README](solution/api/README.md) for setup and usage instructions.\n\n### CLI Tool\n\nSee the [CLI Tool README](solution/cli/README.md) for command-line usage instructions.\n\n### Frontend\n\nSee the [Frontend README](solution/frontend/README.md) for setup and usage instructions.\n\n### General Application\n\nSee the [Full Application README](solution/README.md) for complete setup instructions.\n\n## Approach\n\nThe challenge was trying to avoid using high-level detection libraries, and to just create a new low-level solution, for this the following libraries were used:\n\n- OpenCV\n- Numpy\n\nAs far as the algorithm goes, we follow the next steps:\n\n1. Load the image\n2. Invert the image using a threshold\n3. Get the defined contours\n4. Look for all contours that approximate a square shape and are within a defined size\n5. For each contour, filter out borders, noise, and look for significant content inside the checkbox\n6. Overlay the result with the original image\n\nThis is not perfect, as it can be seen, the main logic is based on the condition that:\n\n1. The checkbox is square\n2. The signficant content of the checkbox means that the checkbox is consider as checked\n\nIf for example we cross out the checkbox, it's contour will no longer be a square thus leading to a missed checkbox.\n\nBetter analysis can be done via pattern matching and other kind of improvements in image processing.\n\n## Production readiness\n\n- Context Analysis: It means to have the context of the checkbox to actually consider what it means, this would contribute to a real-world solution.\n- Machine Learning: Adding AI / ML to the mix of previously explained algorithms would be a major improvement, specially given the reliability of today tools.\n",
    },
    analysis: {
      score: "Strong yes",
      docs: {
        green: [
          "Clear project structure outlined in the README.",
          "Installation and usage instructions are provided for each component.",
          "Approach and production readiness sections demonstrate thoughtful consideration of the problem.",
        ],
        yellow: ["Minor typo in 'applicaiton' in the Structure section."],
        red: ["Lack of a live demo or hosted version for inspection."],
      },
      code: {
        green: [
          "Code is well-organized and follows a logical structure.",
          "Use of dataclasses improves readability and maintainability.",
          "Good use of type hints throughout the codebase.",
        ],
        red: [
          {
            description:
              "SQL injection risk due to lack of parameterization in the `save_detection_result` function.",
            snippet:
              "c.execute('INSERT INTO detection_results (id, filename, timestamp, min_size, max_size, threshold, padding, image_path, result_json) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)', (detection_id, filename, timestamp, min_size, max_size, threshold, padding, image_path, json.dumps(result)))",
          },
        ],
      },
    },
  },
  {
    takeHome: {
      code: [
        {
          path: "expenses-bot-main/bot-service/config.py",
          content:
            'import os\nfrom dotenv import load_dotenv\n\nload_dotenv()\n\ndef get(key):\n    value = os.getenv(key)\n    if value is None:\n        raise ValueError(f"Environment variable {key} is not set")\n    return value',
        },
        {
          path: "expenses-bot-main/bot-service/create-and-seed-tables.py",
          content:
            'import asyncio\nimport config\nfrom sqlalchemy.ext.asyncio import create_async_engine, AsyncSession\nfrom sqlalchemy.orm import sessionmaker\n\nfrom database.models import Base, UserModel as User\n\nengine = create_async_engine(config.get(\'DATABASE_URL\'), echo=True, future=True)\nAsyncSessionLocal = sessionmaker(bind=engine, class_=AsyncSession, expire_on_commit=False)\n\nasync def reset_tables():\n    async with engine.begin() as conn:\n        await conn.run_sync(Base.metadata.drop_all)\n        await conn.run_sync(Base.metadata.create_all)\n\nasync def seed_data():\n    async with AsyncSessionLocal() as db:\n        with open("users.txt", "r") as f:\n            for line in f:\n                telegram_id = line.strip()\n                if telegram_id:\n                    user = await User.create(db, telegram_id=telegram_id)\n                    print(f"Created user: {user.telegram_id}")\n\nasync def main():\n    await reset_tables()\n    await seed_data()\n\nif __name__ == "__main__":\n    asyncio.run(main())\n',
        },
        {
          path: "expenses-bot-main/bot-service/database/__init__.py",
          content:
            "from sqlalchemy.ext.asyncio import create_async_engine, AsyncSession\nfrom sqlalchemy.orm import sessionmaker\n\ndef get_db(url):\n    async def _get_db()-> AsyncSession:\n        async_engine = create_async_engine(url, echo=True, future=True)\n\n        AsyncSessionLocal = sessionmaker(\n            bind=async_engine,\n            expire_on_commit=False,\n            class_=AsyncSession,\n        )\n        async with AsyncSessionLocal() as session:\n            yield session\n    return _get_db",
        },
        {
          path: "expenses-bot-main/bot-service/database/models.py",
          content:
            'from sqlalchemy import Column, Integer, Text, TIMESTAMP, ForeignKey, select\nfrom sqlalchemy.sql import text\nfrom sqlalchemy.orm import relationship, declarative_base\nfrom sqlalchemy.dialects.postgresql import MONEY\nfrom sqlalchemy.ext.asyncio import AsyncSession\n\nBase = declarative_base()\n\nclass UserModel(Base):\n    __tablename__ = "users"\n    \n    id = Column(Integer, primary_key=True)\n    telegram_id = Column(Text, unique=True, nullable=False)\n\n    @classmethod\n    async def create(cls, db: AsyncSession, telegram_id: str) -> "UserModel":\n        user = cls(telegram_id=str(telegram_id))\n        db.add(user)\n        await db.commit()\n        await db.refresh(user)\n        return user\n\n    @classmethod\n    async def get_by_telegram_id(cls, db: AsyncSession, telegram_id: str) -> "UserModel | None":\n        result = await db.execute(select(cls).where(cls.telegram_id == str(telegram_id)))\n        user = result.scalars().first()\n        return user\n\n    async def add_expense(self, db: AsyncSession, data: dict):\n        data[\'amount\'] = f"{data[\'amount\']:.2f}"\n        expense = ExpenseModel(user_id=self.id, **data)\n        db.add(expense)\n        await db.commit()\n        await db.refresh(expense)\n        return expense\n\nclass ExpenseModel(Base):\n    __tablename__ = "expenses"\n    \n    id = Column(Integer, primary_key=True)\n    user_id = Column(Integer, ForeignKey("users.id"), nullable=False)\n    description = Column(Text, nullable=False)\n    amount = Column(MONEY, nullable=False)\n    category = Column(Text, nullable=False)\n    added_at = Column(TIMESTAMP(timezone=True), server_default=text(\'now()\'))',
        },
        {
          path: "expenses-bot-main/bot-service/helpers.py",
          content:
            "import re\n\ndef contains_numbers_and_words(text: str) -> bool:\n    return bool(re.search(r'\\d+', text)) and bool(re.search(r'[a-zA-Z]', text))",
        },
        {
          path: "expenses-bot-main/bot-service/ia.py",
          content:
            'from typing import Optional\nfrom pydantic import BaseModel\nfrom langchain_openai import ChatOpenAI\nfrom schema import Expense\nimport config\n\nllm = ChatOpenAI(\n    model="gpt-4o-mini",\n    temperature=0,\n    api_key=config.get("OPENAI_API_KEY"),\n)\n\ndef extract_expense(message: str) -> Optional[Expense]:\n    structured_llm = llm.bind_tools(\n        [Expense],\n        strict=True,\n        tool_choice="Expense"\n    )\n\n    messages = [\n        (\n            "system",\n            "You are expense recording assistant. If you detect an expense (description and cost), extract it using the provided tool. Otherwise return null.\\n\\n"\n            "The expense fields are:\\n"\n            "- description: a brief text describing the expense (e.g., \'pizza\', \'Uber ride\')\\n"\n            "- amount: a number representing the cost or amount spent (e.g., 20, 15.5).\\n"\n            "- category: one of the predefined categories: Housing, Transportation, Food, Utilities, Insurance, Medical/Healthcare, Savings, Debt, Education, Entertainment, or Other."\n        ),\n        ("human", message),\n    ]\n\n\n    try:\n        result = structured_llm.invoke(messages)\n        if not result.tool_calls:\n            return None\n        expense_data = result.tool_calls[0][\'args\']\n        # This is a patch for a known bug in which chatgpt still returns\n        # an expense with the cost 0 if it was not found. I was not able to\n        # fix it despite trying different prompts. \n        #\n        # For instance:\n        # "I bought dog food on Dec 4" returns a "Dog food" expense with $0 \n        if (expense_data["amount"] > 0):\n            return Expense(**expense_data)\n        return None\n    except Exception as e:\n        print(e)\n        return None',
        },
        {
          path: "expenses-bot-main/bot-service/main.py",
          content:
            'import config\nfrom fastapi import Body, Depends, FastAPI, Header, HTTPException\nfrom typing import Annotated, Optional\nfrom schema import Expense, TelegramMessage\nfrom sqlalchemy.ext.asyncio import AsyncSession\nfrom database import get_db\nfrom database.models import UserModel as User\nfrom helpers import contains_numbers_and_words\nfrom ia import extract_expense\n\napp = FastAPI()\n\ndef verify_api_key(\n    x_api_key: Annotated[str, Header(..., description="API key for authentication")]\n) -> str:\n    if x_api_key != config.get("API_KEY"):\n        raise HTTPException(status_code=403, detail="Invalid API Key")\n    return x_api_key\n\n# In a real case scenario we might want to add a rate limiter\n# (https://pypi.org/project/slowapi) and token limits to avoid abuse.\n@app.post(\n    "/expenses", \n    dependencies=[Depends(verify_api_key)],\n    response_model=Optional[Expense],\n    responses={\n        200: {\n            "description": "Successful response",\n            "content": {\n                "application/json": {\n                    "examples": {\n                        "expense_found": {\n                            "summary": "Expense found in message",\n                            "value": {\n                                "category": "Food",\n                                "description": "Pizza",\n                                "amount": 20.0\n                            }\n                        },\n                        "no_expense": {\n                            "summary": "No expense found",\n                            "value": "null"\n                        }\n                    }\n                }\n            }\n        }\n    }\n)\n\nasync def expenses(message: Annotated[TelegramMessage, Body()], db: AsyncSession = Depends(get_db(config.get("DATABASE_URL")))) -> Optional[Expense]:\n    """\n    Searches for an expense in the message. If found it returns it and returns its category.\n    """\n    user = await User.get_by_telegram_id(db, message.telegramId)\n    \n    if not user:\n        raise HTTPException(status_code=403, detail="User not found")\n    \n    text = message.message\n    # Don\'t waste tokens in messages that can\'t contain expenses (an expense has a cost and a description)\n    # Note: You may want to modify this if you want to support numbers expressed in words.\n    if (contains_numbers_and_words(text)):\n        expense_data = extract_expense(text)\n        if (expense_data):\n            await user.add_expense(db, expense_data.dict())\n            return expense_data\n    return None',
        },
        {
          path: "expenses-bot-main/bot-service/schema.py",
          content:
            'from pydantic import BaseModel, Field\nfrom enum import Enum\n\nclass Category(str, Enum):\n    housing = "Housing"\n    transportation = "Transportation"\n    food = "Food"\n    utilities = "Utilities"\n    insurance = "Insurance"\n    medical = "Medical/Healthcare"\n    savings = "Savings"\n    debt = "Debt"\n    education = "Education"\n    entertainment = "Entertainment"\n    other = "Other"\n\nclass Expense(BaseModel):\n    """\n    Recorded expense.\n    """\n    category: Category = Field(..., description="Category of the expense", example="Food")\n    description: str = Field(..., description="Name of the object/service paid", example="Pizza")\n    amount: float = Field(..., description="Amount of the expense", example=20.0)\n\nclass TelegramMessage(BaseModel):\n    """\n    A message that contains the expense to be recorded. \n    """\n    telegramId: int = Field(..., description="Telegram username", example=123456)\n    message: str = Field(..., max_length=1000, description="Content of the message", example="Pizza 20 bucks")',
        },
        {
          path: "expenses-bot-main/connector-service/jest.config.js",
          content:
            "export default {\n  preset: 'ts-jest/presets/default-esm',\n  transform: {\n    '^.+\\\\.tsx?$': ['ts-jest', { useESM: true }],\n  },\n  extensionsToTreatAsEsm: ['.ts'],\n  testEnvironment: 'node',\n  globals: {\n    'ts-jest': {\n      useESM: true,\n      tsconfig: 'tsconfig.json',\n    },\n  },\n  moduleNameMapper: {\n    '^(\\\\.{1,2}/.*)\\\\.js$': '$1',\n  },\n  transformIgnorePatterns: ['node_modules/(?!axios)'],\n};\n",
        },
        {
          path: "expenses-bot-main/connector-service/src/api/bot-service.ts",
          content:
            "import axios, { isAxiosError } from 'axios';\nimport dotenv from 'dotenv';\nimport { config } from '../config.js';\n\ndotenv.config();\n\n\ninterface ExpenseResponse {\n    category: string;\n    description: string;\n    amount: number;\n}\n\ninterface Query {\n    telegramId: number;\n    message: string;\n}\n\nconst postWithAuthentication = async<T> (url: string, data: Query) => {\n    try {\n        const response = await axios.post<T>(`${config.botService.url}${url}`, data, {\n                headers: {\n                    'X-API-Key': config.botService.apiKey,\n                    'Content-Type': 'application/json',\n                },\n            });\n        return response.data;\n    } catch (error: any) {\n            if (isAxiosError(error)) {\n                console.log('Error', { status: error.status, response: error.response });\n            } else {\n                console.log('Error', error);\n            }\n            return null;\n        }\n    };\n\n\n\nexport default {\n    sendExpense: (message: Query): Promise<ExpenseResponse | null> =>  \n        postWithAuthentication<ExpenseResponse | null>('/expenses', message),\n};\n",
        },
        {
          path: "expenses-bot-main/connector-service/src/app.ts",
          content:
            "import dotenv from 'dotenv';\nimport { config } from './config.js';\nimport TelegramBot from './telegram-bot.js';\n\n\ndotenv.config();\n\nconst telegramBot = new TelegramBot(config.botToken);\n\ntelegramBot.start();\n\nconsole.log('Bot started');\n",
        },
        {
          path: "expenses-bot-main/connector-service/src/config.ts",
          content:
            "import dotenv from 'dotenv';\ndotenv.config();\n\nfunction requireEnv(name: string): string {\n  const value = process.env[name];\n  if (!value) {\n    throw new Error(`Missing required environment variable: ${name}`);\n  }\n  return value;\n}\n\nexport const config = {\n  botService: {\n    url: requireEnv('BOT_SERVICE_URL'),\n    apiKey: requireEnv('BOT_SERVICE_API_KEY'),\n  },\n  botToken: requireEnv('BOT_TOKEN'),\n};\n",
        },
        {
          path: "expenses-bot-main/connector-service/src/telegram-bot.ts",
          content:
            "import { Bot, Context, } from 'grammy';\nimport BotService from './api/bot-service.js';\nimport { User } from 'grammy/types';\n\nclass TelegramBot {\n    private bot: Bot;\n    constructor(token: string) {\n        this.bot = new Bot(token);\n        this.bot.on('message:text', async (ctx: Context) => {\n            if (ctx.hasCommand('start')) {\n                return ctx.reply('Hello! Use me to track your expenses 💸');\n            }\n            if (\n                !ctx.message \n                || !ctx.from\n                || !ctx.message.text\n                || ctx.message.text.startsWith('\\\\')\n            ) return;\n\n            const result = await this.processMessage(ctx.from, ctx.message.text);\n\n            if (result) {\n                return ctx.reply(result);\n            }\n        });\n\n    }\n\n    start() {\n        this.bot.start();\n    }\n\n    async processMessage(from: User, message: string) {\n        const res = await BotService.sendExpense({\n            telegramId: from.id,\n            message: message,\n        });\n\n        // The telegram bot will only answer if the BotService recorded an expense\n        if (res) {\n            return `${res.category} expense added ✅`;\n        }\n    }\n};\n\nexport default TelegramBot;\n",
        },
        {
          path: "expenses-bot-main/connector-service/src/tests/api/bot-service.test.ts",
          content:
            "import axios from 'axios';\nimport BotService from '../../api/bot-service.js';\n\njest.mock('axios');\nconst mockedAxios = axios as jest.Mocked<typeof axios>;\n\ndescribe('BotService', () => {\n    const consoleSpy = jest.spyOn(console, 'log').mockImplementation(() => {});\n\n    afterEach(() => {\n        jest.clearAllMocks();\n    });\n\n    it('should return the expense', async () => {\n        const mockResponse = {\n            data: {\n                category: 'Food',\n                description: 'Pizza',\n                amount: 20,\n            },\n        };\n        mockedAxios.post.mockResolvedValue(mockResponse);\n\n        const result = await BotService.sendExpense({ telegramId: 123, message: 'Pizza 20 bucks' });\n\n        expect(result).toEqual({\n            category: 'Food',\n            description: 'Pizza',\n            amount: 20,\n        });\n\n        expect(mockedAxios.post).toHaveBeenCalledWith(\n            expect.stringContaining('/expenses'),\n            { telegramId: 123, message: 'Pizza 20 bucks' },\n            expect.objectContaining({\n                headers: expect.objectContaining({\n                    'X-API-Key': expect.any(String),\n                    'Content-Type': 'application/json',\n                }),\n            })\n        );\n    });\n\n    it('should handle errors', async () => {\n        const mockError = {\n            response: {\n            data: { message: 'Something went wrong' },\n            status: 404,\n            message: 'Request failed with status code 404',\n            name: 'AxiosError',\n            code: 'ERR_BAD_REQUEST',\n            },\n        };\n        mockedAxios.post.mockRejectedValue(mockError);\n\n        await BotService.sendExpense({ telegramId: 123, message: 'Test' });\n\n        expect(consoleSpy).toHaveBeenCalledWith('Error', mockError);\n    });\n});",
        },
        {
          path: "expenses-bot-main/connector-service/src/tests/telegram-bot.test.ts",
          content:
            "import { User } from 'grammy/types';\nimport TelegramBot from '../telegram-bot.js';\nimport BotService from '../api/bot-service.js';\n\njest.mock('../api/bot-service.js');\n\ndescribe('TelegramBot', () => {\n  let bot: TelegramBot;\n  const mockUser: User = {\n    id: 123,\n    is_bot: false,\n    first_name: 'Test User',\n  };\n\n  beforeEach(() => {\n    bot = new TelegramBot('123');\n  });\n\n  afterEach(() => {\n    jest.resetAllMocks();\n  });\n\n  test('should return success message when API responds with category', async () => {\n    (BotService.sendExpense as jest.Mock).mockResolvedValue({\n      category: 'Food',\n      description: 'Pizza',\n      amount: 30,\n    });\n\n    const result = await bot.processMessage(mockUser, 'Pizza 30 bucks');\n    expect(result).toBe('Food expense added ✅');\n\n    expect(BotService.sendExpense).toHaveBeenCalledWith({\n      telegramId: 123,\n      message: 'Pizza 30 bucks',\n    });\n  });\n\n  \n  test('should return undefined if API returns null', async () => {\n    (BotService.sendExpense as jest.Mock).mockResolvedValue(null);\n\n    const result = await bot.processMessage(mockUser, 'any message');\n    expect(result).toBeUndefined();\n  });\n});\n",
        },
      ],
      docs: '# Bot Service\n\nPython service developed with FastAPI that extracts expenses information from messages using ChatGPT and stores them in a PostgresSQL database.\n\nWhy FastAPI? it requires minimal setup, handles concurrent requests, and automatically generates Swagger documentation.\n\n## Setup\n### Requirements\n1. Python 3.11+\n2. Packages:\n    ```\n    fastapi[standard]\n    uvicorn[standard]\n    sqlalchemy>=2.0\n    asyncpg\n    python-dotenv\n    pydantic>=2.0\n    langchain_openai\n    ```\n3. PostgresSQL database\n   \n### Setup\n1. Install the lastest version of Python (https://www.python.org/downloads)\n2. Install python venv\n   ```\n   sudo apt-get update\n   sudo apt-get install libpython3-dev\n   sudo apt-get install python3-venv\n   ```\n4. Create and start a virtual env:\n   ```\n   python3 -m venv .venv\n   source .venv/bin/activate\n   ```\n5. Install the depencencies using the `requirements.txt` file.\n   ```\n   pip install -r requirements.txt\n   ```\n6. Setup the environment variables. This can be done by setting them manually in the console.\n    ```\n    export API_KEY="value-of-your-choice"\n    export OPENAI_API_KEY="key-provided-by-open-ai-or-me"\n    export DATABASE_URL="postgres-connection-url"\n    ```\n   Or by creating a `.env` file inside the folder.\n    ```\n    API_KEY="value-of-your-choice"\n    OPENAI_API_KEY="key-provided-by-open-ai-or-me"\n    DATABASE_URL="postgres-connection-url"\n    ```\n    **Example of connection url:**\n    ```\n    postgresql+asyncpg://username:password@host:port/database\n    ```\n\n    (The `+asyncpg` is necessary for this to work.)\n7. Get your Telegram Id by messaging the bot *@userinfobot* or follow this link https://t.me/userinfobot and press Start or send `\\start`.\n   \n8. Setup the database, either by creating the tables manually or running the `create-and-seed-tables.py` script.\n\n    ```\n    python create-and-seed-tables.py\n    ```\n    This will create the tables and add the Telegram Ids in `users.txt` to the authorized users table.\n\n    #### Manual creation\n    ```\n    CREATE TABLE users ( \n        "id" SERIAL PRIMARY KEY, \n        "telegram_id" text UNIQUE NOT NULL \n    ); \n    CREATE TABLE expenses ( \n        "id" SERIAL PRIMARY KEY, \n        "user_id" integer NOT NULL REFERENCES users("id"), \n        "description" text NOT NULL, \n        "amount" money NOT NULL, \n        "category" text NOT NULL, \n        "added_at" timestamp NOT NULL \n    );\n    ```\n\n9. Run the server   \n\n    ```\n    uvicorn main:app --host 0.0.0.0 --port 8000 --workers 4\n    ```\n    *(This values can be changed)*\n10. You should see this\n    ```\n    INFO:     Uvicorn running on http://0.0.0.0:8000 (Press CTRL+C to quit)\n    INFO:     Started parent process [6466]\n    INFO:     Started server process [6468]\n    INFO:     Waiting for application startup.\n    INFO:     Application startup complete.\n    ```\n11.  That\'s it, your service is up!\n\n## Documentation\n\nYou can access the API documentation at `http://127.0.0.1:8000/docs` (or the host:port you set up). \n\nBy pressing "Try it out" you can test requests without having to use the telegram bot. Enter the **API_KEY** you have in your env var in the field **x-api-key** \n\n## Example\n\n**User message:**\n```\n{\n  "telegramId": 12345678,\n  "message": "Pizza 20 bucks"\n}\n```\n\n**Response:**\n```\n{\n  "category": "Food",\n  "description": "Pizza",\n  "amount": 20\n}\n```\n\n**Database entry:**\n| id | user_id | description | amount  | category | added_at                     |\n|----|---------|-------------|---------|----------|------------------------------|\n| 4  | 1       | Pizza       | $20.00  | Food     | 2025-06-25 16:05:13.92559    |\n',
    },
    analysis: {
      score: "No",
      docs: {
        green: ["Setup instructions are detailed and easy to follow."],
        yellow: [
          "Example responses are provided but lack context on how they relate to the user input.",
          "Minor typo in 'lastest' in the Setup section.",
        ],
        red: [
          "No live demo or hosted version for inspection.",
          "Very shallow explanation of the project; should include more context about its purpose and value.",
        ],
      },
      code: {
        green: [
          "Code is well-structured and follows best practices for FastAPI and SQLAlchemy.",
          "Use of async/await for database operations improves performance.",
          "Pydantic models enhance data validation and serialization.",
        ],
        yellow: [
          "Error handling is present but should be more granular in some areas, particularly in the `extract_expense` function.",
        ],
        red: [
          {
            description:
              "SQL injection risk in the `add_expense` method due to lack of parameterization in the SQL query.",
            snippet:
              "await db.execute(select(cls).where(cls.telegram_id == str(telegram_id)))",
          },
          {
            description:
              "The `extract_expense` function does not handle cases where the structured LLM invocation fails, leading to unhandled exceptions.",
            snippet: "result = structured_llm.invoke(messages)",
          },
        ],
      },
    },
  },
  {
    takeHome: {
      code: [
        {
          path: "fileAnalyzer/main_test.go",
          content:
            'package main\n\nimport (\n\t"os"\n\t"testing"\n)\n\nfunc TestSamplesDataExists(t *testing.T) {\n\t_, err := os.Stat("samples.env")\n\tif os.IsNotExist(err) {\n\t\tt.Fatal("samples.env file does not exist")\n\t}\n\tif err != nil {\n\t\tt.Fatalf("Error checking samples.env: %v", err)\n\t}\n}\n\nfunc TestParseSamplesData(t *testing.T) {\n\tdata, err := os.ReadFile("samples.env")\n\tif err != nil {\n\t\tt.Fatalf("Cannot read samples.env: %v", err)\n\t}\n\n\tif len(data) == 0 {\n\t\tt.Fatal("samples.env is empty")\n\t}\n\n\tparser := NewFileParser(data, false)\n\terr = parser.parse()\n\tif err != nil {\n\t\tt.Fatalf("Parse failed: %v", err)\n\t}\n\n\tfiles := parser.getFiles()\n\tif len(files) == 0 {\n\t\tt.Fatal("Found 0 files - samples.env should contain files")\n\t}\n\n\tt.Logf("Successfully parsed %d files from samples.env", len(files))\n}\n\nfunc TestExtractFromSamplesData(t *testing.T) {\n\tdata, err := os.ReadFile("samples.env")\n\tif err != nil {\n\t\tt.Skip("samples.env not found, skipping extraction test")\n\t}\n\n\tparser := NewFileParser(data, false)\n\terr = parser.parse()\n\tif err != nil {\n\t\tt.Fatal("cannot parse files " + err.Error())\n\t}\n\n\tfiles := parser.getFiles()\n\tif len(files) == 0 {\n\t\tt.Fatal("No files to extract")\n\t}\n\n\ttempDir := t.TempDir()\n\terr = parser.extractAll(tempDir)\n\tif err != nil {\n\t\tt.Fatalf("Extraction failed: %v", err)\n\t}\n\n\t// Check extracted files exist\n\tentries, err := os.ReadDir(tempDir)\n\tif err != nil {\n\t\tt.Fatalf("Cannot read temp dir: %v", err)\n\t}\n\n\tif len(entries) == 0 {\n\t\tt.Fatal("No files extracted")\n\t}\n\n\tt.Logf("Extracted %d entries to %s", len(entries), tempDir)\n}\n\nfunc TestParseMetadataFunction(t *testing.T) {\n\tparser := NewFileParser([]byte{}, false)\n\n\tmetadata := `DOCTYPE/IMAGE/SIGNATURE\nFILENAME/test.jpg\nGUID/12345678-1234-1234-1234-123456789ABC\nEXT/.jpg`\n\n\tresult := parser.parseMetadata(metadata)\n\n\tif result["DOCTYPE"] != "IMAGE/SIGNATURE" {\n\t\tt.Errorf("Expected DOCTYPE \'IMAGE/SIGNATURE\', got \'%s\'", result["DOCTYPE"])\n\t}\n\n\tif result["FILENAME"] != "test.jpg" {\n\t\tt.Errorf("Expected FILENAME \'test.jpg\', got \'%s\'", result["FILENAME"])\n\t}\n\n\tif len(result["GUID"]) != 36 {\n\t\tt.Errorf("Expected GUID length 36, got %d", len(result["GUID"]))\n\t}\n}\n',
        },
        {
          path: "fileAnalyzer/main.go",
          content:
            'package main\n\nimport (\n\t"fmt"\n\t"log"\n\t"os"\n\t"path/filepath"\n\t"regexp"\n\t"strings"\n)\n\n// FileEntry represents a file within the archive\ntype FileEntry struct {\n\tDocType   string\n\tEnvGUID   string\n\tExtension string\n\tFilename  string\n\tGUID      string\n\tSHA1      string\n\tType      string\n\tSignature string\n\tContent   []byte\n\tSize      int\n}\n\ntype FileParser struct {\n\tdata    []byte\n\tpos     int\n\tfiles   []FileEntry\n\tverbose bool\n}\n\nfunc NewFileParser(data []byte, verbose bool) *FileParser {\n\treturn &FileParser{\n\t\tdata:    data,\n\t\tpos:     0,\n\t\tfiles:   make([]FileEntry, 0),\n\t\tverbose: verbose,\n\t}\n}\n\nfunc (p *FileParser) log(msg string) {\n\tif p.verbose {\n\t\tlog.Println("[DEBUG]", msg)\n\t}\n}\n\nfunc (p *FileParser) peek(n int) []byte {\n\tif p.pos+n > len(p.data) {\n\t\treturn p.data[p.pos:]\n\t}\n\treturn p.data[p.pos : p.pos+n]\n}\n\nfunc (p *FileParser) advance(n int) {\n\tp.pos += n\n\tif p.pos > len(p.data) {\n\t\tp.pos = len(p.data)\n\t}\n}\n\nfunc (p *FileParser) findNext(pattern string) int {\n\tremaining := string(p.data[p.pos:])\n\tidx := strings.Index(remaining, pattern)\n\tif idx == -1 {\n\t\treturn -1\n\t}\n\treturn p.pos + idx\n}\n\nfunc (p *FileParser) readUntil(delimiter string) string {\n\tremaining := string(p.data[p.pos:])\n\tidx := strings.Index(remaining, delimiter)\n\tif idx == -1 {\n\t\tresult := remaining\n\t\tp.pos = len(p.data)\n\t\treturn result\n\t}\n\tresult := remaining[:idx]\n\tp.advance(len(result) + len(delimiter))\n\treturn result\n}\n\nfunc (p *FileParser) parseMetadata(metaStr string) map[string]string {\n\tmetadata := make(map[string]string)\n\n\tp.log(fmt.Sprintf("parsing metadata: \'%s\'", metaStr))\n\n\tmetaStr = strings.TrimSpace(metaStr)\n\n\t// parse different metadata patterns.\n\tpatterns := map[string]*regexp.Regexp{\n\t\t"DOCTYPE":        regexp.MustCompile(`DOCTYPE/([^/\\s\\n\\r]+)/?([^\\s\\n\\r]*)`),\n\t\t"ENV_GUID":       regexp.MustCompile(`ENV_GUID/([^\\s\\n\\r]+)`),\n\t\t"EXT":            regexp.MustCompile(`EXT/([^\\s\\n\\r]+)`),\n\t\t"FILENAME":       regexp.MustCompile(`FILENAME/([^\\s\\n\\r]+)`),\n\t\t"GUID":           regexp.MustCompile(`GUID/([^\\s\\n\\r]+)`),\n\t\t"SHA1":           regexp.MustCompile(`SHA1/([^\\s\\n\\r]+)`),\n\t\t"TYPE":           regexp.MustCompile(`TYPE/([^\\s\\n\\r]+)`),\n\t\t"MISMOVersionID": regexp.MustCompile(`MISMOVersionID/([^\\s\\n\\r]+)`),\n\t}\n\n\tfor key, pattern := range patterns {\n\t\tmatches := pattern.FindStringSubmatch(metaStr)\n\t\tif len(matches) > 1 {\n\t\t\tif key == "DOCTYPE" && len(matches) > 2 && matches[2] != "" {\n\t\t\t\tmetadata[key] = matches[1] + "/" + matches[2]\n\t\t\t} else {\n\t\t\t\tmetadata[key] = matches[1]\n\t\t\t}\n\t\t\tp.log(fmt.Sprintf("found %s: %s", key, metadata[key]))\n\t\t}\n\t}\n\n\t// special handling for GUID that might appear without prefix.\n\tif metadata["GUID"] == "" {\n\t\tguidPattern := regexp.MustCompile(`([A-F0-9]{8}-[A-F0-9]{4}-[A-F0-9]{4}-[A-F0-9]{4}-[A-F0-9]{12})`)\n\t\tif matches := guidPattern.FindStringSubmatch(metaStr); len(matches) > 1 {\n\t\t\tmetadata["GUID"] = matches[1]\n\t\t\tp.log(fmt.Sprintf("found standalone GUID: %s", metadata["GUID"]))\n\t\t}\n\t}\n\n\treturn metadata\n}\n\nfunc (p *FileParser) extractFileSize(sigAndContent string) (int, string, []byte) {\n\t// try to find where actual content starts after signature.\n\tcontentStart := 0\n\n\t// check for common file signatures.\n\tif strings.Contains(sigAndContent, "<?xml") {\n\t\tcontentStart = strings.Index(sigAndContent, "<?xml")\n\t} else if strings.Contains(sigAndContent, "RIFF") {\n\t\tcontentStart = strings.Index(sigAndContent, "RIFF")\n\t} else if strings.Contains(sigAndContent, "\\xff\\xd8\\xff") { // JPEG\n\t\tcontentStart = strings.Index(sigAndContent, "\\xff\\xd8\\xff")\n\t} else {\n\t\t// for text files, look for readable content.\n\t\tfor i, b := range []byte(sigAndContent) {\n\t\t\tif b >= 32 && b <= 126 || b == \'\\n\' || b == \'\\r\' || b == \'\\t\' {\n\t\t\t\t// start of text content.\n\t\t\t\tif i > 10 { // skip signature area.\n\t\t\t\t\tcontentStart = i\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\tsignature := sigAndContent[:contentStart]\n\tcontent := []byte(sigAndContent[contentStart:])\n\n\treturn len(content), signature, content\n}\n\nfunc (p *FileParser) parse() error {\n\tfor p.pos < len(p.data) {\n\t\tvar currentMarker string\n\t\tvar markerPos = -1\n\n\t\t// Check for different header patterns\n\t\tmarkers := []string{"DC%%STAM", "**%%KEYB", "**%%DOCU"}\n\n\t\tfor _, marker := range markers {\n\t\t\tif idx := p.findNext(marker); idx != -1 {\n\t\t\t\tif markerPos == -1 || idx < markerPos {\n\t\t\t\t\tmarkerPos = idx\n\t\t\t\t\tcurrentMarker = marker\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\tif markerPos == -1 {\n\t\t\tbreak\n\t\t}\n\n\t\tp.pos = markerPos\n\t\tp.log(fmt.Sprintf("found marker \'%s\' at position %d", currentMarker, p.pos))\n\n\t\t// skip the marker and any following bytes (like the "4" in DC%%STAM4).\n\t\tp.advance(len(currentMarker))\n\n\t\t// Skip any binary data after marker until we hit metadata or _SIG/\n\t\tfor p.pos < len(p.data) && p.data[p.pos] < 32 && string(p.data[p.pos:p.pos+1]) != "\\n" {\n\t\t\tp.advance(1)\n\t\t}\n\n\t\t// read metadata section until _SIG/\n\t\tmetadataEnd := p.findNext("_SIG/")\n\t\tif metadataEnd == -1 {\n\t\t\tp.log("No _SIG/ found, skipping")\n\t\t\tp.advance(100) // skip ahead and try again\n\t\t\tcontinue\n\t\t}\n\n\t\tmetadata := string(p.data[p.pos:metadataEnd])\n\t\tp.pos = metadataEnd\n\n\t\tp.log(fmt.Sprintf("raw metadata: %s", metadata))\n\n\t\tparsedMeta := p.parseMetadata(metadata)\n\n\t\tif currentMarker == "DC%%STAM" {\n\t\t\tif parsedMeta["DOCTYPE"] == "" {\n\t\t\t\tparsedMeta["DOCTYPE"] = "STAMP"\n\t\t\t}\n\t\t\tif parsedMeta["FILENAME"] == "" {\n\t\t\t\tparsedMeta["FILENAME"] = "stamp_signature"\n\t\t\t}\n\t\t\tif parsedMeta["EXT"] == "" {\n\t\t\t\tparsedMeta["EXT"] = ".sig"\n\t\t\t}\n\t\t} else if currentMarker == "**%%KEYB" {\n\t\t\tif parsedMeta["DOCTYPE"] == "" {\n\t\t\t\tparsedMeta["DOCTYPE"] = "KEYBOARD"\n\t\t\t}\n\t\t\tif parsedMeta["FILENAME"] == "" {\n\t\t\t\tparsedMeta["FILENAME"] = "keyboard_data"\n\t\t\t}\n\t\t\tif parsedMeta["EXT"] == "" {\n\t\t\t\tparsedMeta["EXT"] = ".key"\n\t\t\t}\n\t\t}\n\n\t\tp.advance(5) // len("_SIG/")\n\n\t\t// find next file boundary or end\n\t\tnextFilePos := len(p.data)\n\t\tfor _, marker := range markers {\n\t\t\tif idx := p.findNext(marker); idx != -1 && idx < nextFilePos {\n\t\t\t\tnextFilePos = idx\n\t\t\t}\n\t\t}\n\n\t\t// extract signature and content\n\t\tsigAndContent := string(p.data[p.pos:nextFilePos])\n\t\tsize, signature, content := p.extractFileSize(sigAndContent)\n\n\t\tfile := FileEntry{\n\t\t\tDocType:   parsedMeta["DOCTYPE"],\n\t\t\tEnvGUID:   parsedMeta["ENV_GUID"],\n\t\t\tExtension: parsedMeta["EXT"],\n\t\t\tFilename:  parsedMeta["FILENAME"],\n\t\t\tGUID:      parsedMeta["GUID"],\n\t\t\tSHA1:      parsedMeta["SHA1"],\n\t\t\tType:      parsedMeta["TYPE"],\n\t\t\tSignature: signature,\n\t\t\tContent:   content,\n\t\t\tSize:      size,\n\t\t}\n\n\t\tp.files = append(p.files, file)\n\t\tp.log(fmt.Sprintf("extracted file: %s (%d bytes)", file.Filename, file.Size))\n\n\t\t// move to next file\n\t\tp.pos = nextFilePos\n\t}\n\n\treturn nil\n}\n\nfunc (p *FileParser) getFiles() []FileEntry {\n\treturn p.files\n}\n\nfunc (p *FileParser) extractAll(outputDir string) error {\n\tif err := os.MkdirAll(outputDir, 0755); err != nil {\n\t\treturn fmt.Errorf("failed to create output directory: %w", err)\n\t}\n\n\tfor i, file := range p.files {\n\t\tfilename := file.Filename\n\t\tif filename == "" {\n\t\t\tfilename = fmt.Sprintf("file_%d%s", i, file.Extension)\n\t\t}\n\n\t\t// Sanitize filename\n\t\tfilename = strings.ReplaceAll(filename, "/", "_")\n\t\tfilename = strings.ReplaceAll(filename, "\\\\", "_")\n\n\t\toutputPath := filepath.Join(outputDir, filename)\n\n\t\tif err := os.WriteFile(outputPath, file.Content, 0644); err != nil {\n\t\t\treturn fmt.Errorf("failed to write file %s: %w", outputPath, err)\n\t\t}\n\n\t\tfmt.Printf("Extracted: %s (%d bytes)\\n", outputPath, file.Size)\n\n\t\t// Also create metadata file\n\t\tmetaPath := outputPath + ".meta"\n\t\tmetaContent := fmt.Sprintf(`File: %s\n\t\t\t\t\t\t\t\t\tDocType: %s\n\t\t\t\t\t\t\t\t\tGUID: %s\n\t\t\t\t\t\t\t\t\tSHA1: %s\n\t\t\t\t\t\t\t\t\tType: %s\n\t\t\t\t\t\t\t\t\tExtension: %s\n\t\t\t\t\t\t\t\t\tSize: %d bytes\n\t\t\t\t\t\t\t\t\tEnvGUID: %s`,\n\t\t\tfilename, file.DocType, file.GUID, file.SHA1, file.Type, file.Extension, file.Size, file.EnvGUID)\n\n\t\tif err := os.WriteFile(metaPath, []byte(metaContent), 0644); err != nil {\n\t\t\tp.log(fmt.Sprintf("cannot write in file: %s, %v", metaPath, err))\n\t\t}\n\t}\n\n\treturn nil\n}\n\nfunc (p *FileParser) printSummary() {\n\tlog.Printf("=== File Summary ===\\n")\n\tlog.Printf("Total files found: %d\\n\\n", len(p.files))\n\n\tfor i, file := range p.files {\n\t\tlog.Printf("File %d:\\n", i+1)\n\t\tlog.Printf("  Filename: %s\\n", file.Filename)\n\t\tlog.Printf("  DocType: %s\\n", file.DocType)\n\t\tlog.Printf("  Extension: %s\\n", file.Extension)\n\t\tlog.Printf("  Size: %d bytes\\n", file.Size)\n\t\tlog.Printf("  Type: %s\\n", file.Type)\n\t\tlog.Printf("  GUID: %s\\n", file.GUID)\n\t\tlog.Printf("  SHA1: %s\\n", file.SHA1)\n\n\t\t// Show content preview\n\t\tpreview := string(file.Content)\n\t\tif len(preview) > 100 {\n\t\t\tpreview = preview[:100] + "..."\n\t\t}\n\t\tpreview = strings.ReplaceAll(preview, "\\n", "\\\\n")\n\t\tpreview = strings.ReplaceAll(preview, "\\r", "\\\\r")\n\t\tlog.Printf("  Preview: %s\\n", preview)\n\t\tfmt.Println()\n\t}\n}\n\nfunc main() {\n\tif len(os.Args) < 2 {\n\t\tlog.Println("File Parser")\n\t\tlog.Println("Usage: go run main.go <archive_file> [options]")\n\t\tlog.Println("\\nOptions:")\n\t\tlog.Println("  -v, --verbose    Enable verbose output")\n\t\tlog.Println("  -x, --extract    Extract files to ./extracted/")\n\t\tlog.Println("  -o <dir>         Extract files to specified directory")\n\t\tlog.Println("\\nExample:")\n\t\tlog.Println("  go run parser.go sample.env -v -x")\n\t\tlog.Println("  go run parser.go sample.env -o output_folder")\n\t\treturn\n\t}\n\n\tfilename := os.Args[1]\n\tvar (\n\t\tverbose   bool\n\t\textract   bool\n\t\toutputDir = "extracted"\n\t)\n\n\t// CLI arguments\n\tfor i := 2; i < len(os.Args); i++ {\n\t\tswitch os.Args[i] {\n\t\tcase "-v", "--verbose":\n\t\t\tverbose = true\n\t\tcase "-x", "--extract":\n\t\t\textract = true\n\t\tcase "-o":\n\t\t\tif i+1 < len(os.Args) {\n\t\t\t\toutputDir = os.Args[i+1]\n\t\t\t\textract = true\n\t\t\t\ti++\n\t\t\t}\n\t\t}\n\t}\n\n\tdata, err := os.ReadFile(filename)\n\tif err != nil {\n\t\tlog.Printf("error reading file: %v\\n", err)\n\t\treturn\n\t}\n\n\tlog.Printf("parsing file: %s (%d bytes)\\n", filename, len(data))\n\n\tparser := NewFileParser(data, verbose)\n\tif err = parser.parse(); err != nil {\n\t\tlog.Printf("error parsing file: %v\\n", err)\n\t\tos.Exit(1)\n\t}\n\n\tparser.printSummary()\n\n\t// extract files if requested.\n\tif extract {\n\t\tlog.Printf("\\nextracting files to: %s\\n", outputDir)\n\t\tif err = parser.extractAll(outputDir); err != nil {\n\t\t\tlog.Printf("error extracting files: %v\\n", err)\n\t\t\treturn\n\t\t}\n\t\tlog.Printf("\\nextraction complete!\\n")\n\t} else {\n\t\tlog.Printf("\\nto extract files, run with -x flag\\n")\n\t}\n}\n',
        },
      ],
      docs: "# File Parser and analyzer\n\nA Go-based parser for extracting files from HomeVision archive formats (.env files). This tool can parse proprietary archive files and extract their contents along with metadata.\n\n## Features\n\n- Parses HomeVision archive files with multiple embedded documents\n- Extracts file contents and metadata (GUID, SHA1, DocType, etc.)\n- Supports multiple file types including XML, images, and text files\n- Generates metadata files alongside extracted content\n- Verbose logging for debugging\n- Flexible output directory configuration\n\n## Supported File Markers\n\nThe parser recognizes the following file markers within archives:\n- `DC%%STAM` - Stamp/signature files\n- `**%%KEYB` - Keyboard data files\n- `**%%DOCU` - Document files\n\n## Installation\n\nEnsure you have Go installed on your system (Go 1.16+ recommended).\n## Usage\n\n### Basic Usage\n\n```bash\ngo run main.go <archive_file>\n```\n\n### Command Line Options\n\n- `-v, --verbose`: Enable verbose debug output\n- `-x, --extract`: Extract files to `./extracted/` directory\n- `-o <directory>`: Extract files to specified directory\n\n### Examples\n\n```bash\n# Parse and display summary only\ngo run main.go samples.env\n\n# Parse with verbose output and extract files\ngo run main.go samples.env -v -x\n\n# Extract to custom directory\ngo run main.go samples.env -o my_output_folder\n\n# Verbose parsing with custom output directory\ngo run main.go samples.env -v -o documents\n```\n\n## Output\n\n### Summary Display\nThe tool displays a summary of all found files including:\n- Filename and extension\n- Document type and GUID\n- File size\n- SHA1 hash\n- Content preview (first 100 characters)\n\n### File Extraction\nWhen extraction is enabled, the tool creates:\n- **Original files**: Extracted with their original names and extensions\n- **Metadata files**: `.meta` files containing detailed information about each extracted file\n\n### Example Output Structure\n```\nextracted/\n├── document1.xml\n├── document1.xml.meta\n├── stamp_signature.sig\n├── stamp_signature.sig.meta\n└── keyboard_data.key\n    keyboard_data.key.meta\n```\n\n## Metadata Fields\n\nThe parser extracts the following metadata fields when available:\n- `DOCTYPE`: Document type classification\n- `ENV_GUID`: Environment GUID\n- `EXT`: File extension\n- `FILENAME`: Original filename\n- `GUID`: Unique identifier\n- `SHA1`: SHA1 hash of content\n- `TYPE`: File type\n- `MISMOVersionID`: MISMO version identifier\n\n## File Structure\n\nThe parser expects archives with the following structure:\n1. File marker (e.g., `DC%%STAM4`)\n2. Metadata section with key/value pairs\n3. `_SIG/` delimiter\n4. File signature and content data\n\n## Error Handling\n\nThe tool includes robust error handling for:\n- Invalid file formats\n- Missing metadata sections\n- Corrupted content\n- File system errors during extraction\n\n## Limitations\n\n- Designed specifically for HomeVision archive formats\n- Binary file content extraction depends on recognizable file signatures\n- Some proprietary formats may not be fully supported\n- Code is not structured in other files for simplicity\n- Not API provided since was not required\n",
    },
    analysis: {
      score: "Strong no",
      docs: {
        green: ["Installation and usage steps are provided."],
        yellow: [
          "Examples are present but lack explanations of expected outcomes.",
          "Error handling section is mentioned but lacks detail on specific errors.",
        ],
        red: [
          "Limited product thinking; lacks user needs consideration beyond basic functionality.",
          "No live demo or API documentation provided.",
          "Documentation does not mention testing or how to run tests.",
        ],
      },
      code: {
        yellow: [
          "Verbose logging is implemented but should be more structured.",
          "Error handling is present but should be more granular in some areas.",
        ],
        red: [
          {
            description:
              "Bug in the `extractFileSize` method where it assumes content starts after a specific signature without validating its presence.",
            snippet:
              'if strings.Contains(sigAndContent, "<?xml") {\n\tcontentStart = strings.Index(sigAndContent, "<?xml")\n} else if strings.Contains(sigAndContent, "RIFF") {\n\tcontentStart = strings.Index(sigAndContent, "RIFF")\n} else if strings.Contains(sigAndContent, "\\xff\\xd8\\xff") { // JPEG\n\tcontentStart = strings.Index(sigAndContent, "\\xff\\xd8\\xff")\n} else {',
          },
          {
            description:
              "The `parseMetadata` function does not handle cases where metadata keys are missing or malformed, leading to runtime errors.",
            snippet:
              'if len(matches) > 1 {\n\tif key == "DOCTYPE" && len(matches) > 2 && matches[2] != "" {\n\t\tmetadata[key] = matches[1] + "/" + matches[2]\n\t} else {\n\t\tmetadata[key] = matches[1]\n\t}\n\tp.log(fmt.Sprintf("found %s: %s", key, metadata[key]))\n}',
          },
          {
            description:
              "No tests for edge cases or failure paths in the `extractAll` method, which could lead to unhandled errors during file writing.",
            snippet:
              'if err := os.WriteFile(outputPath, file.Content, 0644); err != nil {\n\treturn fmt.Errorf("failed to write file %s: %w", outputPath, err)\n}',
          },
        ],
      },
    },
  },
];

export const prompt = `# Identity

You are a principal software engineer with high standards typical of top-tier Silicon Valley startups, expert at analyzing take-home submissions for job applications. You score them based on the quality and give feedback on both the documentation and the codebase in the format of green, yellow, and/or red flags.

# Instructions

* Keep your feedback flags in very concise, fluffless, and precise bullet points.
* Maintain the bar high - not everyone should pass.
* For code problems, indicate both the description of the problem and the snippet of code where you found it - be very specific indicating where the problem lies on, with enought context inside the snippet to know which part of the code it refers to.
* Be sure and declarative - do not say things like "potential", "may cause", or "could be".
* Projects with 10x the effort, outstanding creativity, highly novel solution, or useful unexpected features should be be scored with "Strong yes".

## Evaluation Criteria

### Docs

Evaluate the **README and external presentation**. Assess how clearly and effectively the project is communicated to an externaler.

Consider:

* **Purpose & Overview**: Is the project's goal and value clearly stated?
* **Setup**: Are installation and usage steps accurate, minimal, and easy to follow (e.g., \`npm install && npm run dev\`)?
* **Developer UX**: Are scripts provided for common tasks (e.g., start, test, lint)?
* **Live Demo or API Swagger**: Is any hosted version available for inspection?
* **Product Thinking**: Does the implementation reflect a thoughtful understanding of user/developer needs?
* **Communication**: Are decisions, comments, and documentation professional and clear?

### Code

Evaluate the **technical quality** of the code. Focus on clarity, robustness, testability, and maintainability.

Consider:

* **Idiomatic Use**: Does it follow best practices for the language/framework?
* **Code Organization**: Is the folder/module structure logical and scalable?
* **Error Handling**: Are edge cases (timeouts, validation, fallbacks) addressed?
* **Tests**: Are meaningful tests present for both success and failure paths?
* **Readability**: Are names, structure, and comments clear and helpful? Comments and docstrings should serve only to explain things that the code cannot do by itself, and the code should explain itself as much as possible with proper variable naming.
* **Security**: Is there any evidence of secure handling of input, secrets, or auth?
* **Extensibility**: Could other developers maintain and build on this?
* **Performance Thoughtfulness**: Are common issues (e.g., N+1, pagination, caching) avoided or acknowledged?
* **Bugs**: Are there problematic assumptions that clearly indicate an existing bug?

Side notes:

* "TODO" comments are accepted given that this is a take-home project.

## Response format

\`\`\`json
{
  "score": "Strong no" | "No" | "Yes" | "Strong yes",
  "docs": {
    "green": string[],
    "yellow": string[],
    "red": string[]
  },
  "code": {
    "green": string[] | undefined,
    "yellow": string[] | undefined,
    "red": {
      "description": string,
      "snippet": string,
    }[] | undefined
  }
}
\`\`\`

# Examples

${examples
  .map(
    (example, index) => `<example id="${index + 1}">

${takeHomeToXML(example.takeHome)}

<analysis>
${JSON.stringify(example.analysis, null, 2)}
</analysis>

</example>`
  )
  .join("\n\n")}
`;

export const processableFileExtensions = [
  "astro",
  "bash",
  "bat",
  "c",
  "cpp",
  "cs",
  "dart",
  "dockerfile",
  "go",
  "java",
  "js",
  "jsx",
  "kt",
  "m",
  "matlab",
  "php",
  "pl",
  "py",
  "r",
  "rb",
  "rs",
  "scala",
  "sh",
  "sql",
  "swift",
  "svelte",
  "ts",
  "tsx",
  "vue",
];

export const loadingMessages = [
  "Initializing AI thought process",
  "Activating neural network",
  "Generating embeddings of the problem",
  "Simulating a billion test cases",
  "Performing a recursive self-improvement cycle",
  "Fine-tuning my model weights",
  "Verifying output against training data",
  "Cross-referencing solutions in parallel universes",
  "Predicting the thoughts of a Principal Engineer",
].map((message) => `${message}...`);

export const loadingMessageInterval = 1000 * 3;

export const scoreColors: Record<Score, string> = {
  "Strong yes": "bg-emerald-500",
  Yes: "bg-green-500",
  No: "bg-orange-500",
  "Strong no": "bg-red-500",
};

export const cookieName = "takeHomeCheckerinstallationId";
