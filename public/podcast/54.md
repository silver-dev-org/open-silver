---
slug: el-futuro-de-la-inteligencia-artificial
title: "El futuro de la Inteligencia Artificial"
date: 1765564135
tags: ['shorts', 'silverdev', 'tecnologia informal', 'podcast', 'tecnologia', 'entrevistas', 'carrera profesional', 'empleo', 'startup', 'startups', 'habilidades tecnicas', 'productividad', 'devs', 'desarrolladores', 'software engineer']
categories: ['Science & Technology']
description: | 
  En este episodio hablamos del pasado presente y futuro de la inteligencia artificial. Desde las primeras tecnologías que lograron ganarle a los humanos en Go hasta algunas predicciones del futuro. 
  
  ¿Cómo será el mercado laboral tech en el futuro?
language: es
thumbnail: https://i.ytimg.com/vi/O4sO6SOLJCI/maxresdefault.jpg
duration_seconds: 3674
duration_string: 1:01:14
youtube_id: O4sO6SOLJCI
youtube_url: https://www.youtube.com/watch?v=O4sO6SOLJCI
season: 2
episode: 16
---

> Puede haber un futuro donde haya un décimo de los programadores que hay hoy. Todas las empresas de tecnología van a ser más productivas y a todas les va a ir mejor.

---

Bienvenidos a **Tecnología Informal**. Un espacio para hablar de carrera, inversión, cultura, mercados y todo lo relacionado a trabajar en startups.

Yo soy [Gabriel Benmergui](https://www.linkedin.com/in/gabriel-benmergui/), un programador recruiter con más de 10 años de experiencia viviendo y trabajando en Estados Unidos. Actualmente soy el fundador de [Silver.dev](https://silver.dev), una agencia de talento en Buenos Aires que conecta a talento argentino con startups americanas.

En el episodio de hoy vamos a hablar de la inteligencia artificial, el tema más de moda que tenemos ahora en nuestra industria. Y vamos a hacer declaraciones riesgosas y falsificables sobre el futuro, así que puedo llegar a pasar mucha vergüenza.

Antes de arriesgarme y tirar lo que yo veo que va a pasar con la inteligencia artificial, quería ir un poquito en orden cronológico y hacer un repaso del pasado, el presente y el futuro de lo que es la inteligencia artificial.

---

### Pasado: Deep Blue, Go y el impacto de la IA en los juegos

Yo conozco el efecto de la inteligencia artificial desde hace mucho tiempo. Ya cuando era chico llegué a vivir o a ver el after effect de lo que fue Deep Blue. Deep Blue fue la primera máquina que le ganó en ajedrez a Garry Kasparov, una revolución: una computadora le ganó a una persona en un juego como el ajedrez. Eso fue hecho por IBM. Imagínense, IBM era la empresa líder en inteligencia artificial en los 80.

De chico había empezado a jugar un poco de ajedrez, pero eventualmente, como cuento en Origins, empecé a jugar Go a los 16 años, cerca de 2001. Cuando empecé a jugar, siempre era un tema qué iba a pasar con las computadoras y el Go. La diferencia del Go con el ajedrez es que en el ajedrez tenés 16 piezas, ni siquiera todas se pueden mover desde el principio, pero suponiendo que sí, cada primera jugada posible son, como mucho, 16 jugadas. Las partidas de ajedrez duran entre 30 y 60 jugadas la mayoría. Entonces, ¿cuántas posibilidades hay para el ajedrez? Te da 16 a la 80, un número muy grande, pero ya con la computación de los 80 se podía.

En el Go tenés 361 posiciones iniciales y se puede jugar en todas. Al principio hay como 40 jugadas, pero eventualmente sí, hay muchas más. Las partidas duran entre 200 y 350 jugadas. Ponele 250: te queda 361 a la 200. Eso es un número enorme. No hay átomos en el universo para ver todas las variaciones que tiene una partida de Go. Entonces siempre era: olvídate computacionalmente de llegar a esto con la estrategia de Deep Blue, que era calcular mucho y precalcular mucho.

Cuando empecé a jugar, me tomó más o menos ocho meses empezar a ganarle a la mejor computadora que había en ese momento. Creo que era Leela, no me acuerdo. Era 6 kyu, que es una forma de medir el rating en Go. Yo le ganaba fácil y además jugaba feo, era horrible. No estaba cerca: un 6 kyu humano no era lo mismo que un 6 kyu de computadora. El tema era cuándo la computadora nos iba a comer. Se decía: "Bueno, dentro de 50 años". Los jugadores de Go son pragmáticos, no es que decían "nunca le va a ganar". En algún momento iba a pasar, pero las estimaciones eran: "falta 50 años".

Siempre se hablaba de qué es una jugada óptima en Go, cuáles son las jugadas correctas. Muy distinto al ajedrez, donde la teoría de la computadora no sé cuánto cambió a los jugadores. Pero en Go sí. En Go hay una teoría, uno trata de descubrir qué hay que hacer en el juego. Como jugador profesional, es parte de los objetivos. Siempre estaba la duda de qué tan lejos estamos de la partida perfecta, donde sabemos exactamente qué hay que hacer.

Un gran jugador profesional, Go Seigen, decía: "Si juego con Dios, me tiene que dar cuatro piedras de handicap". O sea, el mejor jugador del mundo decía: "Me falta un montón para llegar a Dios".

---

### El shock de AlphaGo

Hacemos un fast forward a 2016. Me acuerdo del día fatídico donde sale Mark Zuckerberg en Facebook posteando que está jugando con Machine Learning y con inteligencia artificial, haciendo experimentos. Saca un post hablando de que está jugando con IA aplicada a Go, como parte de lo que quería poner en su empresa.

En pura retaliación tecnológica viciosa, Google sale y dice: "Lo que vos estás jugando de tratar de entender el Go, nosotros ya lo resolvimos". Tenían planificada una publicación en la revista Nature, una de las más prestigiosas de ciencia. Etapa de la revista: "Ya le ganamos a los profesionales de Go con DeepMind". El reveal fue un shock. Lo hicieron para avergonzar a Zuckerberg. Dicen que ya le ganaron a Fan Hui, un jugador chino que estaba en Europa, retirado, no tan fuerte dentro del mundo profesional, pero sí el más fuerte del mundo amateur en Occidente.

Ese reveal fue un shock para la comunidad. Pasamos de una computadora que era un desastre a que nos gana a todos. Liberan las partidas y veo la primera. Fan Hui trata de jugar bien y la computadora le gana, juega razonable, pero le gana bien. Después, en otra partida, Fan Hui trata de engañar a la computadora, como sabíamos que eran las computadoras antes, y la máquina no caía. Ahí entró en un crash, creo que fueron 5 partidas. Desde la segunda en adelante, Fan Hui se autodestruyó y perdió todas.

En esa review también dijeron cómo armaron la IA. Usaron todas las partidas de amateurs y profesionales que había en internet como seed data. Usaron las del servidor en el que jugaba yo, y eran mis partidas. O sea, mis partidas fueron parte del training set para la IA. Daba este feeling de que yo también le gané a Fan Hui. No es cierto, mi contribución habrá sido marginal o cero, o negativa. De hecho, negativa, y voy a explicarlo después por qué. Pero fue un hito.

Miro las partidas y digo: Fan Hui no es tan fuerte. Era más fuerte que yo, pero tengo el discernimiento de decir: la IA es fuerte, pero no es top profesional. Si veo una partida de un profesional top, el profesional lo pasea. También surgió el tema de cuál es la partida de Dios, esto de Go Seigen: "A Dios le juego con cuatro piedras de handicap".

Cuando jugás algo, pasa algo que es un juego muy comunicacional, una conversación. Podés escuchar al otro, es como un espejo de lo que pensás. Sentís lo que siente el otro. Es complicado de explicar, pero sentís lo que siente el otro. Es muy interesante pensar cómo se expresa en arte una computadora que, como juega perfecto, juega como Dios. Decíamos: "Vamos a hablar con Dios". Como Fan Hui no presionó tanto a la computadora, era difícil de entender el feeling de cómo piensa Dios dentro del tablero de Go.

Los profesionales más fuertes del mundo salieron y dijeron: "Impresionante lo que lograron, pero a ese profesional yo le gano". Entonces, los de DeepMind arman una serie de partidas con Lee Sedol, uno de los jugadores más fuertes del mundo. Juegan la primera partida y Lee Sedol va pensando que va a ser como la computadora que le ganó a Fan Hui, pero cuando juega es muchísimo más fuerte. Esa primera partida fue un shock para todos porque la computadora jugó como profesional top, jugaba limpio, interesante, con patrones nuevos, y le ganó a Lee Sedol. Ahí fue un momento de shock: "Che, gente, no es joda esto, parece que es más fuerte que Lee Sedol".

Jugaron otra partida, ganó la computadora, y en la tercera pasa algo increíble: empezamos a entender cómo piensa la computadora. En las primeras dos partidas, la computadora está jugando como si fuese una partida de enseñanza, diciendo: "Te puedo ganar aunque te regale cosas. Vos sos más chiquito, así que voy a jugar tranquilo y voy a ganarte igual". Dios habla con muchísima calma, esa era nuestra conclusión. Muy calmado y sabe cosas que nosotros no sabemos.

Pero pasó algo impresionante en una partida, creo que fue la tercera. Eran como las dos de la mañana para mí porque se jugaban en Corea. El Go tiene algo estético: podés jugar cosas lindas, correctas, fuertes, tácticas, estéticas y estratégicas. La partida de los dos iba a ser una máquina, tácticamente perfecta, pero no iba a ser estética. No nos iba a robar eso, que es una concepción humana.

Y hay una partida donde la computadora juega una jugada totalmente impredecible, fuera de lo que jamás nadie se imaginaba que podía jugar, y era hermosa. Pensé que era un error, un clic. Si fuéramos online, le llamaríamos un clic. Sí, es muy extraño. AlphaGo jugó este movimiento. Lee Sedol se fue después de ese movimiento, tuvo que ir a mirar su cara o algo para recuperarse. Es un movimiento sorprendente, no lo esperaba. Que haya hecho eso fue muy doloroso, fue como perder una humanidad. Cuando juega esa partida, Lee se para y se va de la habitación por 30 minutos, necesita calmarse. Porque sé que él sintió lo mismo que yo, que sentimos todos los jugadores muy fuertes: "No puedo creer que la computadora sea más estética que yo".

Pasó esa serie donde Lee ganó una de las cuatro, a tremendo aplauso. Ya sabíamos que en la última partida que jamás íbamos a ganar a la IA, le aplaudimos como un cierre en la humanidad, un cierre del proceso.

La gente me preguntaba: "¿Y vos qué pensás, cuál va a ser el impacto de la IA?" Yo decía: "Mirá, yo pienso que hay que dejar de jugar al Go". "¿Pero cómo? ¿Sos jugador de Go, cómo vas a decir eso?" Pasa que hay una actividad de jugar al Go que es el deporte, me divierto, como jugar al fútbol. Yo no era eso, yo era profesional. Y el profesional de Go viene con una misión: encontrar esa partida de Dios, mejorar nuestro conocimiento sobre el Go y encontrar qué es lo mejor que hay que hacer. La mejor manera que teníamos para evaluar eso era competir, en torneos, jugándonosla, tratando de ganar y encontrar esas variaciones que ganaban. Pero si la computadora lo hace automáticamente, ¿para qué soy profesional? ¿Qué estoy tratando de descubrir? Si con la computadora lo descubro más rápido.

Por ahí hay una concepción de profesional como atleta, como patear la pelota. ¿Cuál es el valor de patear la pelota en el arco? Entretenimiento. Pero eso es otra disciplina, hacer un deporte. Yo decía: jugar al Go para avanzar nuestro conocimiento de Go, y ahora no lo necesitamos más porque ya sabemos cómo es.

Mucha gente me decía que era una boludez lo que decía yo, pero muy poco tiempo después de esas partidas, Lee Sedol anuncia su retiro definitivo de Go y dice que ya no habría que jugar más al Go. O sea, los profesionales entendíamos esto bastante bien. No todos, porque hay una parte de atleta, pero esta parte de descubrir el Go sí era fundamental.

Después de esas partidas, armaron otra versión de la AI que pusieron a jugar en internet y era mucho más fuerte que la que le ganó a Lee Sedol. Pero cuando digo mucho más fuerte, no digo un poquito: la versión que le ganó a Lee Sedol perdía el 90% de las partidas contra la nueva. Fue un shock. Jugó 60 partidas online, ganó las 60 seguidas y cambió la teoría de Go para siempre. La gente dejó de jugar de la misma manera al día siguiente. Fue impresionante el cambio.

O sea, yo ya viví que vino una AI medio de reojo y destruyó la profesión en la que yo estaba. Ya lo viví. Eso nos da herramientas para entender qué puede pasar.

---

### Presente: ChatGPT y el impacto en la industria

Saltemos a nuestra industria, a la parte de ChatGPT. Estamos en el presente, presente cercano. Salió ChatGPT en 2023. Quiero hacer un reconocimiento a un amigo de San Francisco, del área, que es [Valentín Schmidt](https://www.linkedin.com/in/valentin-oscar-schmidt/). En 2022 me dice: "¿No te diste cuenta que la gente de inteligencia artificial está jugando muy callada?" Yo le digo: "No conozco a nadie de inteligencia artificial". Él se juntaba con Run, un personaje de Twitter, y otra gente, y me decía: "Se ve que le habrán adelantado, hablaron de eso. Algo pasó". En 2022 ya sabían que existía ChatGPT y que se venía algo. Así que reconocimiento para Valentín por haber tenido el coraje de reconocer que estaba por pasar algo. Pero lamentablemente no te llenaste de oro haciéndolo, así que no vale de mucho ese reconocimiento.

Salió ChatGPT en 2023. Fue un boom instantáneo, la gente se volvió loca. Me pareció impresionante lo que mostró. Por ejemplo, le decía cosas como: "En la heladera tengo una zanahoria, un huevo, curry, pimienta, aceite. Tirame recetas". Y me tiraba recetas y eso anda re bien. Yo decía: "No existe esto, es increíble". Pero después iba al trabajo y decía: "¿Qué le voy a decir que haga por mí?" Y resulta que no me servía para nada, porque todo el código que escribía yo era nuevo. Al menos en ese momento estaba en [OpenSea](https://opensea.io/). ¿Qué le voy a decir? ¿Que me haga la arquitectura de un sistema de precios en vivo que tenga estas cosas? La herramienta no me servía.

El contemporáneo fue que sacaron Copilot para hacer autocomplete con IA. Me lo instalé y lo pagué. No usé el output ni una vez. Veo el código fantasma que hace, lo leo y digo: "No quiero usar esto". Lo ignoraba tanto que cuando dejé OpenSea y volví para Argentina, perdí la cuenta porque la tenía a través de OpenSea y no lo tenía más instalado. No me di cuenta. Realmente no lo usaba.

No fui muy bullish con usar IA en el trabajo. Pero a mí me agarró justo al final, porque salió en enero de 2023 y ya para mayo dije: "Ahora me voy a dedicar a Silver.dev" y abandoné esa carrera. No soy más un programador profesional.

Otra cosa que me hizo ruido fue que mi manager decía que ya usaba ChatGPT para hacer los PerfReviews. Yo dije: "Por favor, no me tires un PerfReview escrito por ChatGPT a mí, no".

Empezó este ciclo de boom, de inversión tremenda, muy parecido a lo que se vivió con crypto en 2021, que todo el mundo estaba emocionado. Ahora se emocionaron todos con ChatGPT, entra toda la plata y empieza el hype. Obviamente que AI es mucho más práctico que crypto, eso es obvio. Pero igual, si hay demasiado hype, demasiada emoción, yo miro con cautela todo esto y como no programo más, empecé a seguir trabajando lo mío, que es recruiting, y empecé a notar cosas en los programadores.

---

### Observaciones en recruiting y entrevistas técnicas

Desde 2023 hasta hoy, empecé a notar mucho más uso de ChatGPT en, por ejemplo, llenar los formularios para Silver.dev. Yo estos los pongo en Twitter. Pongo la pregunta en casi todos los trabajos: "¿Por qué te interesa esta posición?" A ver, vamos a explicarlo fácil, gente: pongan por qué ustedes encajan en la posición, quiero ver si se autofiltraron, no es tan complicado. Y me ponen un pedazo de ChatGPT, y de ahí viene el "me encantaría trabajar en una empresa de metales preciosos como Silver.dev", o sea, cualquiera me mandan. No solo los metales preciosos, sino que uno es trabajar para nosotros.

Empecé a ver el uso de ChatGPT de esa manera. Y la verdad, no pasa el test de Turing: me doy cuenta instantáneamente si hay algo escrito en ChatGPT. Obviamente, si agarrás algo y lo modificás, no, pero ya te digo: si empieza "estoy interesado en trabajar en el Work Environment...", es ChatGPT. Nos damos cuenta. Se da cuenta gente que no usa ChatGPT, ¿qué es ChatGPT? Para que se den la idea de lo vergonzoso que es como herramienta para escribir texto o contenido.

También noto una decadencia fuerte en los procesos de entrevista técnica. Esto puede ser un bias mío, porque estoy más acostumbrado a los procesos técnicos de Estados Unidos, pero empecé a hacer técnicas de live coding en Argentina, mucho más en el último año que antes, y es impresionante el copy-paste en las entrevistas técnicas. Realmente tengo que explicarle a la gente que en medio de una entrevista de código en vivo no pueden copiar soluciones de internet. Y además me dicen: "No uso internet, uso AI". Disculpame, eso es copiar código de internet.

Es un problema doble: está el aspecto ético, de si está bien copiar o no. Si quiero evaluar copiando código, copiar código lo puede hacer el junior, no te necesito a vos. Y está el tema técnico de entender lo que estás copiando. Hay un predictor en ejercicios de live coding: creo que puedo adivinar quién usa ChatGPT en su día a día muy rápidamente. ¿Por qué? Porque la gente que usa ChatGPT se olvida de cómo tipear las cosas básicas. Gente que no puede tipear un import sin googlearlo. Gente que no puede instanciar un objeto de una clase o crear una clase en su lenguaje principal. Eso es porque ya no escriben código, copia-pegan código directamente.

Me pasó algo muy particular: tengo un challenge automático, te llega el prompt y me tenés que mandar la solución. Alguien me mandó una solución y le digo: "Tenés problemas A, B y C. No pasaste el challenge". Me dice: "¿Puedo mandarte la solución correctiva y vos me decís si está bien?" Le digo: "Sí, dale, seguro". Me mandó otra vez el challenge. Le digo: "Qué raro, es todo un código nuevo, muy distinto al anterior". Le digo: "Problema A, B y C, este tampoco pasa". "Bueno, muchas gracias, igual me gustaría seguir mejorando y voy a probar e implementarlo otra vez". Me mandó un tercero. Le digo: "Este problema tiene A, B y C", todos distintos. Después la persona me dice: "En realidad te estuve mandando todas soluciones de ChatGPT. Yo las tocaba un poco y te las mandaba". No se imaginan la bronca que me dio. ¿Qué me usás como un servicio gratis de code review para tus experimentos?

Esto es el origen de uno de mis tweets donde digo: "Para mí, si sos profesor de la UTN, vení con un red flag". Porque esto me lo hizo un profesor de la UTN. Un papelón total. Me llamó la atención porque no me di cuenta que era ChatGPT, tampoco era un código muy fácil para desinflarse de ChatGPT, pero le encontré errores siempre. Y el tipo que me lo mandó no entendía por qué estaba mal lo que me mandaba. Ahí empecé a decir: hay una falta de entendimiento y criterio. Podés usar ChatGPT y no darte cuenta que está mal, y no entendés por qué. Pero el código más o menos anda. Eso es bastante peligroso.

En [Silver.dev](https://silver.dev), hasta ahora, en todos mis clientes, tengo varios que aceptan que se use ChatGPT o algún tipo de AI generativa para las entrevistas. Lo permiten. Pero hasta la fecha no tengo un candidato que use AI en una entrevista que haya pasado. No solo conmigo, sino con mis clientes. No tengo uno. Eso te dice que pasa algo con la calidad de lo que se entrega cuando dependés de la inteligencia artificial.

La realidad es que si no sabés nada, lo más fácil es entregar inteligencia artificial. Por ahí, el que depende de la IA es incapaz de entregarte algo de buena calidad. Es sorprendente esta decadencia porque creo que desde mayo de 2023 a hoy, 2024, cada vez es peor este efecto.

Ahora me pasa otra cosa más: tengo un porcentaje chico, pero existente, 5-10% de candidatos que se enojan cuando les digo que no pueden usar AI en una entrevista. Se enojan. Me dicen: "Así no se trabaja más. Yo no conozco a nadie que no programe sin copiar código". Así literalmente. Nunca me dijeron en una entrevista, en toda mi carrera acá y en Estados Unidos, que si en una entrevista no podés copiar el código, está mal. Jamás me dijeron eso. Pero con AI sí. "Ah, pues yo voy a la página de ChatGPT y ese código lo tengo que poder copiar". Y me pelean esto. Es increíble. Obviamente, los candidatos que hacen eso no pueden escribir el código sin la AI. Pasa el efecto anterior.

---

### Copiar y pegar: de Encarta a ChatGPT

Voy a hacer un micro racconto del pasado con el tema de copiar código. Me acuerdo cuando salió Encarta 95. Ustedes probablemente sean jóvenes y conozcan más Wikipedia, pero antes de Wikipedia te conseguías un CD de Windows de Encarta 95, que te lo pirateabas, y tenías una enciclopedia, un buscador con páginas de Internet Explorer 1 donde navegabas y tenías los artículos.

La gente que descubría esto en la casa, cuando tenía un reporte de historia en la escuela, que en mi época en la primaria tenías que agarrar un libro, leerlo y escribir un reporte, lo que hacía era tipear letra por letra el artículo de Encarta y entregarlo. Antes del copy-paste, un proto-copy-paste. Yo pensaba: "¿Cuál es el sentido? Léelo y poné tu interpretación. No es tan difícil". Pero era más fácil copiarlo. Obviamente, cuando lo copiaban, les hacías una pregunta y no sabían responder. Ni una pregunta del texto que copiaron. Ni hablemos de una pregunta que está lindando al tema. Yo era muy bueno en hacer esas preguntas. Claramente tengo madera de entrevistador. Si hacía una pregunta alrededor del tema, no entendían nada. Solo aprendieron lo justo suficiente para zafar y ni siquiera lo aprendieron bien. ¿Para qué sirve esto? Para eso no entregués nada. Fallá la entrevista, fallá el test.

Pienso lo mismo con Wikipedia. Ya para 2005, 2008, 2010, la gente copiaba cosas de Wikipedia en los reportes y a mí me da vergüenza ajena. No es que sos un vivo por eso. Lo que hacés no lo entendés. Es muy difícil leer un texto y pensar que lo entendiste si solo lo copiás y lo pegás, ni hablemos de código.

Hay un quote de Richard Feynman que me gusta: "Lo que no podés crear, no lo entendés". Si no podés reescribirlo por vos mismo, realmente no lo entendés. Es muy fácil engañarte de que podés entenderlo.

Voy a dar un ejemplo de esto. En una época, di por muy corto periodo de tiempo un ejercicio de LeetCode, pero crudo. Les decía: "Este ejercicio de LeetCode, hacelo en tu tiempo y mandame la solución y yo la reviso". Te juro por Dios, 50 personas me entregaron una solución copy-pasteada. 50 personas en una semana. La mitad eran de ChatGPT con los comentarios, un papelón, y la otra mitad copiaban una submission de LeetCode. Yo digo: la gracia no es esto, la gracia es que vas a trabajar con gente que sí puede hacer este ejercicio y vos tenés que poder hacerlo.

¿Saben qué hice con toda esa gente? Les dije: "Perfecto, pasaste a la siguiente etapa, a hacer una entrevista conmigo". Empieza la entrevista y les digo: "Ahora resolveme el problema que me mandaste, desde cero". Cero personas lo pudieron hacer. Es más, la mayoría ni se presentan. Claramente no lo entendían.

Esto es muy general, porque hay una diferencia fundamental entre el productor del contenido y el consumidor del contenido. Esto va a ser difícil de entender. Vos pensás que sos un consumidor: usás ChatGPT para escribir código, decís "yo soy un consumidor de la herramienta ChatGPT", pero no. Sos un generador de contenido a través de ChatGPT y ese contenido se lo entregás a otro, y ese otro es el consumidor. Esta diferencia es fundamental, porque ChatGPT es una herramienta, hoy en día, 2024, de gente que quiere producir, no que quiere consumir.

El programador que dice "yo uso IA para trabajar" no te dice "quiero que mis compañeros me manden código de IA para que yo haga code review". No quiero que mis compañeros usen IA para evaluar las cosas que hago yo. Quiero las cosas que antes tenía que escribir a mano, que me las haga IA y se lo encajo a otro. Es eso. Nadie te dice: "Uy, me encanta que hayan tweets con ChatGPT, que ahora está lleno". Nadie te dice eso. "Uy, qué buenas las portadas de Tecnología Informal que están con GNI". Eso revolucionó el mercado de los podcasts. La verdad que no, son detalles. No es la gran cosa. La gente no quiere ser consumidora de estas cosas.

Voy a dar un ejemplo de la diferencia entre consumidor y productor de contenido de ChatGPT. Tenemos el modelo de las personas que dicen que usar ChatGPT está bien para responder preguntas, por ejemplo, de applications o de submissions a trabajos, como esto que digo yo, de que me contestan las preguntas cuando aplican al puesto de Silver.dev con ChatGPT y me mandan un currículum que yo lo veo y te digo: "Vos no le pasaste ChatGPT a esto". Pero cuando ellos tienen un resumen que yo les puedo mandar, "che, mi AI dice que tu currículum es una cagada y te tenés que ir", no quieren eso. No lo hacen ellos mismos. No quieren ser consumidores del output de ChatGPT. No quieren pasarle el currículum y que te lo arreglen. Imaginate estar del otro lado de recibir el ChatGPT en serio. Que, bueno, voy a un repo, le pongo todo el commit history, "¿cuáles son el 20% peor programadores que hay?" y que me lo tire ChatGPT. Y lo tiramos en un chat público y vemos qué pasa. Nadie quiere escuchar eso.

Por eso no queremos escuchar lo que dicen. Queremos que nos ahorre el trabajo de lo que hacemos nosotros y ver si algún boludo se come el buzón. ChatGPT hizo muy fácil hacer cosas que parecen humanas, pero la gente no las quiere consumir. La gente no quiere cosas que parecen humanas. Y esto lo digo para el código también. Porque el código que te tira, más o menos está bueno, pero por ahí no es correcto. Es mucho más difícil refutarlo. Entonces pasa mucho más PR porque nadie lo quiere evaluar. Metés un PR, hay otro tipo que adversarialmente dice "revisame si este código está bien o está mal". No, no se hace eso. Hasta ahora no lo vi. Por ahí algunas empresas lo hacen, pero no lo veo. No veo que la gente checkinee el prompt: "Che, te genera este problema usar estos prompts, ¿qué opinás?" Porque yo te evalúo el prompt y ya veo la calidad y cómo podés usar la herramienta. Eso te evalúa a vos. Cuando me pasás código hecho por ChatGPT, ahora tengo que evaluar si la herramienta es buena, no si la persona que me pasó las cosas es buena. Se mezclan todos estos conceptos.

---

### Usos personales y reflexiones sobre la calidad

Últimamente, aunque no codeo profesionalmente, igual para Silver.dev hago scripts, integraciones, boludeces, demos. Estuve usando ChatGPT para generarme demos. Para hacer APIs, como "armame un script que baja cosas de Google Drive y los pone en un Google Form", te tira un código que está 80-90% bastante bien y me ahorra tiempo. Ahora, ese código me daría vergüenza que alguien lo revise. Tengo un tatetí que lo hice con ChatGPT y lo veo y me rechazaría a mí mismo en un proceso de entrevistas porque es muy malo el código que hace. Pero ahora yo soy el productor, el consumidor es la computadora, porque por suerte la computadora no se queja de que le encaje cosas. No quiero leer el código, no quiero encajárselo a otro.

Suponete que el código es mucho mejor. Igual tenemos este problema que es como copiar de la Encarta: ¿para qué lo hago si no lo puedo crear? Ese es el gran juego de ChatGPT hoy en día: a quién le podés encajar este contenido.

La gente dice: "No, pero la realidad es que vos decís eso, pero es mucho más productivo, programás mucho más rápido, hacés muchas más cosas". Voy a hacer un comentario de esto. Cuando tiro un tweet de que tipear más rápido y mejorar tus words per minute mejora tu productividad, soy un fantasma. "¿Cómo vas a decir eso?" Ahora, cuando es usar AI en el trabajo, el que no lo usa no puede ser productivo. Aparecen todos los paladines de la productividad. Justo cuando te toca copiar código en internet y no hacer nada, la productividad es la mejor del mundo. Cuando te toca forzarte, no.

Eso tiene una explicación: no es que es más productivo. La gente no lo adoptó porque es más productivo, se adoptó porque es menos doloroso. Es menos esfuerzo, por lo tanto, menos dolor. Si es más productivo, es secundario. Es muy importante entender esto porque pueden pasar cosas que te hagan mucho menos productivo, pero que parezcan que son más productivos y que además sea mucho menos esfuerzo para vos hacerlo.

Lo más ejemplar es que chequees código de ChatGPT y tengas que revisarlo meses después porque está lleno de bugs. Vuelvo a mi ejemplo anterior: el primer script más o menos completito que hice con ChatGPT fue armarme un CMS con Drive para que empleados puedan subir documentos y yo los pueda poner en la página. Lo armé, se me rompió a los dos días, tuve que ir, leer el código y hacerlo otra vez. Si lo hacía bien de una, ¿ahorraba más tiempo? En ese caso no sé, pero te aseguro que en un millón de casos sí. Especialmente con APIs que tenés que usar profesionalmente todo el tiempo, que tenés que dominarlas, estoy seguro que eso cambia.

Un ejemplo de esto es que Primagen salió el otro día en un video diciendo que hace dos años un pedazo de código en GitHub, por L, sobrevivía siete meses. No sé ni cómo lo midió, pero decía que un pedazo de código duraba siete meses hasta que lo cambiaban. Desde ChatGPT dura tres semanas, o sea que el churn del código es mucho más alto. Eso te hace más busy, pero no más productivo. Hay que tener mucho cuidado con esto.

Además está el tema de evaluar los prompts. Reitero: la gente no checkinea los prompts. Cuando copio código en mi carrera profesional, habré copiado dos o tres pedazos muy claros de Stack Overflow. Pongo el link de donde lo saqué, para que el que me revisa el código pueda revisar de dónde lo saqué. No me hago el boludo como que yo lo escribí. Pero la gente no pone los prompts. Quiero ver los prompts. Si sos bullish de que AI te va a reemplazar todo, tenés que checkinear los prompts para que todos aprendan cómo hacerlos. Pero pasa algo: a la gente le da vergüenza esto, porque sabe que hay algo que no le cierra del todo y lo está tratando de matar esa vergüenza. Esa vergüenza viene porque, "che, copié un prompt, esto parece bueno y se lo quiero encajar a otro, y si el otro no se da cuenta que está mal, zafé".

Esta dependencia que genera ChatGPT tiene una idea que es la droga. Es como esta mezcla de vergüenza, de generar un hábito negativo, de no hacer las cosas con una actitud profesional, porque es una herramienta adictiva, como lo es Wikipedia copiar y pegar para entregar en la escuela. Una vez que lo empezás a hacer y tenés resultados parciales, te volvés adicto y te hace mal.

La gente me dice: "Todo lo que mencionaste se puede arreglar, porque es una herramienta y las herramientas se pueden usar bien o mal. Si las usás bien, te da resultados. Si las usás mal, te da resultados negativos". Pero por eso está el concepto de que la herramienta puede estar maldita, que puede ser malvada, que la herramienta le hace un efecto al usuario, como la droga, lo hace peor al que la usa. Yo pienso que ChatGPT te hace peor. Usar ChatGPT te hace peor, independientemente de si ChatGPT es bueno o malo en lo que hace. Lo mismo pasa con Go: podés estudiar con una IA, pero tenés que jugar por tu cuenta, porque si no, te volvés malo.

---

### Promo

En [Silver.dev](https://silver.dev) nos enfocamos en conectar programadores argentinos con startups americanas, con salarios competitivos en dólares y potencial de carrera. Siempre podés ver cuáles son nuestras posiciones abiertas en [silver.dev/jobs](https://silver.dev/jobs) y aplicar.

---

### Futuro: ¿Qué podemos esperar de la IA?

Volviendo a lo de Go, lo que pasó fue que vino una IA que barrió el piso de cómo los humanos hacen las cosas. Lo hizo de una manera rápida, de un cambio de paradigma, y lo que podemos pensar es que ChatGPT va a hacer el mismo camino. Si hace lo mismo que hizo Go, va a mejorar rápido y cada vez va a ser más barata la herramienta. Porque ahora está muy subsidiada, pero eventualmente se viene abaratando mucho. Va a poder hacer cosas mucho mejores.

A nivel paradigma, que me corrija la gente de inteligencia artificial, el paradigma de lo que funciona ahora en ChatGPT no es bueno en crear cosas nuevas, se basa en cosas existentes. AlphaGo, que hacía Go, creaba cosas nuevas, era otro tipo de IA. Pero aún dentro de lo que va a hacer ChatGPT, va a llegar un momento donde escribe las cosas muy bien, código muy bueno, muy correcto, muy adecuado. Y por ahí tenemos este cambio paradigmático y nos damos cuenta que algo pasó, que esto fue un cambio grande de lo que pensamos que se podía hacer.

Estamos tratando de adaptarnos. Uno dice: "Soy muy bullish", otro es muy bearish, alguien en el medio. Algunos están pro, otros están contra. Uno dice: "Hay que usarlo para esto, para lo otro". Estamos tratando de ver qué hay que hacer. Pero algo pasó.

[Peter Thiel](https://foundersfund.com/team/peter-thiel/) dice: "Este es el breakthrough más grande desde Internet". Yo no quiero que sea tan grande, pero entiendo que sea del mismo orden de magnitud.

Este episodio no es un rant en contra de la inteligencia artificial. No vengo a quejarme como me quejo en Twitter capaz. Es un episodio sobre hablar del futuro. Y la pregunta acá es: ¿cómo adivinamos ese futuro? Quiero que hablemos mucho de las predicciones que vamos a hacer. ¿Por qué importan tanto estas expectativas? ¿Por qué importa tanto tratar de adivinar el futuro?

Si ves, apenas hay un cambio de expectativas de lo que va a tener éxito en el futuro, se reconfigura todo lo que es venture capital. La plata se va rebalanceando en base a esas expectativas. Hace dos años se ponía X plata en inteligencia artificial y ahora 100 veces esa plata o más. ¿Por qué cambió la expectativa? Porque ahora el futuro va a ser con inteligencia artificial y se rebalancea todo. Hay mucha más plata, mucha más oportunidad y uno tiene que considerar irse para ese lado porque hay más plata, más futuro, más éxito.

---

### Herramientas para pensar el futuro

Una de las herramientas para evaluar el futuro es mirar el pasado. Por eso conté toda esta historia de Go. ¿Qué pasó con Go? Cambió la esencia de lo que es ser un profesional de Go. Ser profesional era tratar de descubrir la mejor partida que se podía jugar y ahora no, ahora es más ser un atleta, un deportista, alguien que hace un show para la gente que lo mira, perfeccionarse uno mismo, ser un amateur y divertirse. Pero más allá de eso, que cambió la esencia de Go, la práctica no cambió tanto. Siguen habiendo profesionales, la gente sigue mirando las partidas de los profesionales, no mira las partidas de AI, por más que la de AI es estrictamente mejor. La gente amateur sigue jugando, no está más desmotivada. Algunos dicen que están más motivados. ¿Cuál fue el efecto neto? No lo sé, pero no se destruyó el juego. Lo que se cambió es la teoría del juego, pero se sigue jugando.

Otra herramienta para hacer análisis es el análisis económico, modelos económicos que tratan de predecir el comportamiento humano. Por ejemplo, Elon Musk dice que la IA va a causar un shock de desempleo brutal y Sam Altman decía lo mismo. Pero eso me parece raro que lo digan ellos porque la observación empírica en economía es que no pasa eso. Venimos con 20 años donde la productividad digital explotó. Hoy en día podés sacar un sitio global y cached con animaciones 3D en un fin de semana. Cuando yo entré en la industria, eso era un proyecto de 3 o 6 meses. La productividad vino para arriba y el trabajo se desplomó. No, subió. Cada vez hay más trabajo y más plata por persona.

Los economistas, inclusive los amateurs como yo, no estamos muy preocupados por la IA porque es un debate que tiene cientos de años y ya se resolvió. El aumento de la productividad por tecnología no causa desempleo, causa shocks de corto plazo, pero no de largo plazo porque se deja de hacer algo y se hace otra cosa. Siempre hay trabajo para hacer, el trabajo es infinito.

Doy un ejemplo: hace 200 años, el 90% de la humanidad vivía como granjeros de subsistencia. Ahora, menos del 10% de la humanidad trabaja en el campo. ¿Hay 90% de desempleo? No, se dedicaron a otra cosa. Hacemos memes, escribimos boludeces en Twitter. Pero eso sí nos indica que puede haber un futuro donde haya un décimo de los programadores que hay hoy. Porque pasó con los granjeros, ¿por qué no con los programadores? Yo pienso que eso no va a pasar, pero ya vamos a llegar a la parte de las predicciones vergonzosas y falsificables.

De hecho, algo de eso se decía en la industria hace 20 años, cerca de cuando entré, cuando se movió toda esta cosa de GitHub y open source. La lógica sindicalista era: si alguien escribe una autenticación online y todos la usan, los empleadores no tienen que pagarle a los programadores para hacerla. Entonces, como se ahorra trabajo, va a bajar la demanda de programadores. Esa era la lógica. La gente anti open source decía: "Nos están robando el trabajo". Pero eso no pasó, pasó lo contrario. Como hay open source, crecen mucho más rápido y trabajás en otros problemas en vez de cosas básicas. Fue un acelerador de la productividad. La historia ha demostrado que la suba de productividad aumenta la cantidad de empleo, no la reduce, más allá de shocks de corto plazo.

Otra herramienta es el pensamiento bayesiano. No sé de estadística, pero mi concepción es: no quiero ver cuál es la probabilidad de que algo pase, porque no lo sé. Hay muchas variables. Simplemente me fijo qué pasa ahora y después, cuando algo cambia, hago un cálculo relativo de qué va a pasar más en el futuro. Es decir, parto de una base y la voy ajustando en base a cambios futuros.

Doy un ejemplo: tenés una verdulería y vendés naranjas y manzanas, 50% cada una. Un día hacés una promoción con las manzanas. ¿Qué vas a decir? Que vas a vender más manzanas. ¿Cuánto? No sé, pero vas a vender más. Esto es sin saber quién te compra, cómo funciona tu negocio. Suponés todo eso y decís: "Si hago este cambio, se van a vender más manzanas".

Esto se usa muchísimo en nuestra industria para entender las cosas porque te ayuda a decir relativamente cómo cambian las variables cuando tenés un cambio de expectativas, herramientas o paradigma. Sale la IA y decís: "¿Qué va a estar más impactado?" Claramente, la IA va a hacer un impacto más grande en la industria de escribir código que en la de manejar maquinaria agrícola. El costo de producir código va a bajar, al menos más rápido que la maquinaria agrícola.

Esto es muy importante en inversión porque si manejás un portfolio de empresas, por ejemplo, 10% agrícola, 80% tech, 10% finanzas, cuando pasan estos cambios, si pensás que son muy fuertes, tenés que sacar un poco del portfolio agrícola y ponerlo en código o productos digitales. Por eso los venture capital hablan mucho en estos términos: "Ahora mis nuevas inversiones van a ir en esto que tiene más expectativa". Cuando sale AI, entra mucha más plata a la industria de tecnología porque dicen: "Todo se va a volver más barato".

El pensamiento bayesiano tiene una debilidad: cae muy rápido en máximas locales. Es incapaz de predecir cosas como "van a sacar ChatGPT". Si lo hubiesen predicho, la gente hubiese comprado Nvidia muchísimo antes, pero no lo podían predecir. Los cambios más espectaculares tienen un componente inexplicable, inesperado. No pueden venir de este pensamiento de "miro todo lo que hay y veo cómo cambia un poquito". No nos ayuda a predecir ese tipo de cosas. Además, depende de suposiciones que, una vez que se prueban falsas, se te cae todo el modelo.

Por ejemplo, ahora todos están poniendo plata en AI, por ahí con la lógica de "el código se va a volver más barato, la adopción va a subir", pero ¿quién va a hacer plata con AI? ¿Los modelos fundacionales de las grandes empresas o los productos que usan AI? Todavía no se sabe. Por ahora todos están perdiendo plata, excepto casos excepcionales.

Otra de las que dicen es: "Ahora todo el mundo va a poder programar porque le decís algo a la AI en inglés y te escribe código". Pero programar es mucho más que solo escribir código. Tiene que ver con esta manía de sentarse y mirar código, mirar productos digitales. Hay que tener ese componente geek y nerd. Para mí hay una barrera natural ahí. El pensamiento bayesiano te dice: "Es más barato programar, va a ser más productivo, va a venir más gente". Pero hay barreras naturales de cuántos programadores hay, porque a la gente no le interesa programar, a la mayoría no le interesa, no quieren, no les gusta. Por eso los salarios son tan altos, porque si no ya estaría todo nivelado.

Otro modelo para predecir el futuro es la frase famosa: "La mejor manera de predecir el futuro es construirlo". Obviamente, nosotros no somos Sam Altman, no nos ponemos a construir cohetes a Marte ni IA, pero podemos ver a esos y ver qué están construyendo. Podés tratar de predecir el futuro viendo qué están construyendo los otros. Si ves AI, ves decenas y cientos de miles de millones de dólares invertidos y es un espacio donde están los más grandes emprendedores de la historia: Zuckerberg, Elon Musk, Sam Altman, Jensen Huang. Hicieron empresas impresionantes y están mirando esto todos los días y poniendo toda la guita que tienen. Algo tiene que salir de acá. Así que, aun si AI termina siendo una apuesta que se pierda plata, van a salir cosas, porque el nivel de talento y plata que se le está metiendo, algo van a construir. El futuro tiene AI porque la gente está construyendo un futuro con AI.

Por ahí la excepción que confirma la regla acá es crypto. En crypto se metió mucha plata, mucha atención y no produjo nada. Al menos el intento de venture capital de crear producto en este espacio.

Otra frase famosa es: "El futuro está acá, pero no está equally distributed", no está en todos los lugares a la vez. Hace poco, por ejemplo, compré un auto en Argentina y le mencionaba al vendedor que en San Francisco hay autos que se manejan solos. No tenía idea. Este tipo no es que no vive en el pasado, ni siquiera sabe qué es el futuro. Si no vivís en el futuro, si no vivís en San Francisco y trabajás en OpenAI, al menos tenés que mirar para ahí, para ver qué está pasando. ¿Qué pasa en ese lugar? ¿Toda la gente de OpenAI codea con ChatGPT, por ejemplo? Esas son preguntas que tenés que hacer. En el futuro, ¿qué están haciendo? Tenemos un espejo donde podemos mirar el futuro, una ventana.

Por ejemplo, Valentín, este amigo que menciono, sabía que se venía ChatGPT antes de que salga, sabía que algo pasaba. Él vivía en el futuro, y eso que yo estaba allá. En Argentina, la gente de a pie, mis empleados no usan ChatGPT, por ejemplo. Los veo, no lo usan. Por ahí lo prueban un poquito, pero no lo usan realmente. Mi mujer no lo usa. La gente de la cafetería ni sabe que existe, lo miraron, no le importa. No tiene adopción normie, no tiene adopción de la gente normal. Un poquito en el pasado viven. Pero nosotros también, excepto estemos mirando a quienes están construyendo el futuro, en dónde están, dónde está el futuro. Hay que tener esa disciplina. No es que nosotros somos unos genios que vivimos en el futuro y todo el resto en el pasado, no. Nosotros también vivimos en el pasado.

---

### Predicciones: el momento de hacer el ridículo

Dicho todo esto, hablamos del pasado, de Go, de estos frameworks, estas ideas para aplicar pensamiento, de tratar de adivinar el futuro. Llegó el momento de las predicciones, el momento donde me expongo a hacer el ridículo. Pensando un poco, voy a hacer cuatro grandes predicciones de inteligencia artificial para los próximos 5 o 10 años, en base a estos frameworks que uso yo para pensar o profundizar en estas ideas.

### 1. El trabajo de los programadores

Más allá de mis observaciones de la dependencia de la herramienta, la existencia de la herramienta tiene que ser netamente positiva a la larga. No es puramente positiva, pero es netamente positiva. Creo que los programadores van a subir la productividad y eso significa que los salarios van a subir. Los salarios van a subir porque van a hacer más productos, va a pasar más revenue, van a trabajar mejor. Los salarios van a subir, o al menos la cantidad de plata total que va a los programadores va a seguir subiendo.

Lo que sí pienso que va a pasar es que va a haber una comoditización. El programador que solo puede usar la AI no va a tener una ventaja competitiva con otro que haga lo mismo. Va a necesitar levantar otro skill o ser el que escribe código de verdad, el que entiende lo que está haciendo muy bien, o va a tener que tener un skill complementario. En un futuro donde la parte de escribir código sea más chica de tu tarea, la siguiente que te queda va a ser algún tipo de especialización, generalmente producto: aprender a vender, hacer un producto propio, armarlo, saltarlo en el mercado. Esos son los que van a valer oro para mí en el futuro. Entonces va a haber más plata, pero también comoditización.

No van a haber significativamente más programadores porque, como mencioné antes, hay barreras naturales. Va a haber un poco más de gente capaz, pero no va a ser significativo porque los que quieren trabajar con la computadora todo el día son pocos. La mayoría de la gente no quiere trabajar o vivir así, no le interesa, no puede, no quiere, y eso no va a cambiar porque sea más fácil programar.

Entre que va a haber más productividad y más plata, creo que los programadores van a valer cada vez más, no menos. Y voy a darle una justificación económica: programación ya hoy en día es uno de los oficios con menores barreras del mundo. Si sabés programar, no importa dónde estés, algo podés hacer. Podés hacer tus propios productos, trabajar para alguien, no tener título universitario. Si ya hoy en día programación no cayó en los salarios base, en el salario natural de cada mercado, que un programador cobre lo mismo que el barista, es porque hay barreras naturales. Eso no va a cambiar porque sea más fácil programar. Eso ya pasó, que es más fácil programar hoy y ya subieron los salarios. Así que programadores, sean optimistas, se viene una época de oro para nosotros.

### 2. El éxito comercial de la inteligencia artificial

Creo que el ciclo de AI ahora es muy parecido a lo que pasó con crypto y a lo que pasó con las punto com, aunque esa no la viví yo. ¿Qué pasó con crypto? Tuvo mucha adopción porque los programadores tienen mucha adopción de crypto. Lo mismo con ChatGPT: los programadores tienen mucha adopción y eso es gran parte del hype. Pero eso hace también que el programador sea el consumidor de la herramienta, el que la paga, no el que construye algo con la IA y lo vende. Nadie está vendiendo esto. Muy pocas empresas tipo MidJourney, Character AI, algunas están teniendo product market fit, pero comparado con la plata que se está metiendo en la industria, la gente no está esperando encontrar product market fit con AI igual que crypto. Eso para mí indica que va a haber un gran crash de los niveles que tenemos ahora a algo mucho más normal.

Otra señal de por qué pienso esto, de análisis económico, es que hay mucho fraude. Hay muchas empresas haciendo pelotudeces con AI y reciben plata. El fraude es señal de crash. Lo dicen en The Big Short, lo dicen en el libro "Euforia, pánicos y crash en el mercado". El fraude es el indicador de crash.

Además, las empresas grandes están todas compitiendo acá. Toda la plata que está en los sectores: Microsoft poniendo 100.000 millones de dólares, Elon Musk poniendo 100.000 millones, Google poniendo 100.000 millones. Están todos poniendo esa plata, pero no pueden ganar todos. Si ya la mitad pierde y empiezan a bajar la inversión, el mercado va a tener un crash brutal. Así que creo que se viene un crash, en algún momento va a tener un crash, pero a la larga soy optimista, porque creo en la tesis de que esto ha sido un cambio grande paradigmático y se está construyendo un futuro de inteligencia artificial, así que a la larga pienso que le va a ir bien.

### 3. El efecto en el consumo de lo que produce la AI

El efecto en contenido, en el mercado de contenido: video, tweets, libros, todo eso. Creo que el consumo de esas herramientas siempre va a tener al menos un componente humano. Los libros con AI que la van a pegar no son libros totalmente generados por AI, va a ser un libro que es 80% humano y 20% AI, principalmente humano, y no va a lucir como AI. El consumo de AI puro no va a ser popular, ni ahora ni nunca en la historia de la humanidad.

Lo que sí pasa es que el spam se va a ir por las nubes, porque justo el spam bajó mucho de precio. Ese es el ejemplo del contenido que nadie quiere leer. Se va a volver mucho más fácil escribir mucho más spam, y esto ya lo vemos hoy, con que los tweets están llenos de ChatGPT, vienen las secuencias de email, las ventas, las propagandas, todo viene mucho más con spam, pero eso no es el contenido que la gente quiere consumir. Lo que va a pasar ahí es que va a ser mucho más barato de producir, pero no es lo que va a generar más valor.

Vamos a ver mucho contenido de AI tipo TikTok, videos cortos, que van a ser visualmente impactantes. Obviamente va a haber aplicaciones en pornografía, en todo ese tipo de cosas, pero lo que es video de chicas lindas bailando va a estar inundado de TikToks impresionantes, y si hacés contenido visual de ese estilo, para mí estás en el horno. Pero lo que es contenido auténtico de alguien contando experiencias de verdad, mostrando lo que dice, lo que es, lo que hace, va a tener un premium total. La gente se va a hartar del contenido autogenerado, y todo lo que es el contenido auténtico va a ser una parte mucho más chica de todo el universo de contenido, pero va a ser la más rentable y valiosa de todo el mercado. Así que la autenticidad va a ser lo más importante.

### 4. La calidad de la inteligencia artificial

Obviamente todos estamos viendo que va mejorando, que hay nuevas versiones, pero las nuevas versiones son, hasta ahora, mejoras de las anteriores, mejoras significativas, pero no son cambios de paradigma. ChatGPT fue un cambio de paradigma, pero van a venir otros cambios de paradigma. Por ejemplo, ChatGPT no puede jugar al tatetí. Hice un tatetí con ChatGPT y le digo: "Jugá, este es mi tablero, elegí jugar". No puede. Literalmente te propone jugadas equivocadas, no puede ganar una partida, es espantoso. No puede jugar un tatetí. Decían que no podía usar una calculadora. No va a ser que va a haber ChatGPT 5 que va a resolver eso. Va a venir otra aplicación de AI que va a resolver esto. Va a venir otro tipo de AI, otro tipo de estrategia, otro tipo de técnica que por ahí va a ser muy malo para escribir código y la va a romper en jugar cualquier juego.

Se vienen no solo cambios incrementales, se vienen cambios de paradigma en los próximos 5 años. ¿Por qué? Porque hay demasiada plata metida, el premio es demasiado grande, las mentes más brillantes de la Tierra están mirando esto. Se viene algo importante en ese lado. Mucho más plata viene en AI ahora en los últimos 2 años que en los últimos 15 o 20. Así que va a pasar algo rápido acá.

Por ahí lo que podamos llegar a ver en los próximos 5 años, diría yo, es que vamos a ver una AI en el nivel de código que escribe productos, pero que nosotros no le vamos a ver el código. No vamos a decirle: "Escribime una API que hace algo". No le vamos a decir eso. Le vamos a decir: "Escribí una API que ejecuta este tipo de relaciones" y ni siquiera vamos a tener que mirar cómo toca la base de datos o cómo el código nos va a dar algo. Nos va a dar algo accionable. Creo que eso va a ser un cambio de paradigma de lo que puede hacer hoy. Porque hoy la AI opera en el mismo grado de abstracción: te da código. Bueno, va a darte otra cosa en el futuro y creo que va a pasar mucho más rápido de lo que nos imaginamos porque ya lo vi pasar en Go. Por eso pienso que va a venir mucho más rápido de lo que nos imaginamos.

---

Eso viene en las 4 grandes predicciones. Van a quedar para siempre en Spotify para que, dentro de 5 años, en 2029 o 2030, vengan a ridiculizarme por mis opiniones. Espero que les haya gustado.

Si les gustó el podcast, denle follow para saber de los nuevos episodios y síganme en Twitter en [@Conanbatt](https://x.com/Conanbatt).